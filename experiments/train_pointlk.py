"""
    Example for training a tracker (PointNet-LK).

    No-noise version.
"""

import argparse
import os
import sys
import logging
import numpy
import torch
import torch.utils.data
import torchvision
import time
import gc
import copy
import glob
import random
import math
import traceback

# addpath('../')
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir)))
import ptlk
from ptlk import attention_v1
from ptlk import mamba3d_v1  # å¯¼å…¥Mamba3Dæ¨¡å—
from ptlk import fast_point_attention  # å¯¼å…¥å¿«é€Ÿç‚¹æ³¨æ„åŠ›æ¨¡å—
from ptlk import cformer  # å¯¼å…¥Cformeræ¨¡å—

LOGGER = logging.getLogger(__name__)
LOGGER.addHandler(logging.NullHandler())


def options(argv=None):
    parser = argparse.ArgumentParser(description='PointNet-LK')

    # required.
    parser.add_argument('-o', '--outfile', required=True, type=str,
                        metavar='BASENAME', help='output filename (prefix)') # the result: ${BASENAME}_model_best.pth
    parser.add_argument('-i', '--dataset-path', required=True, type=str,
                        metavar='PATH', help='path to the input dataset') # like '/path/to/ModelNet40'
    parser.add_argument('-c', '--categoryfile', required=True, type=str,
                        metavar='PATH', help='path to the categories to be trained') # eg. './sampledata/modelnet40_half1.txt'

    # settings for input data
    parser.add_argument('--dataset-type', default='modelnet', choices=['modelnet', 'shapenet2', 'c3vd'],
                        metavar='DATASET', help='dataset type (default: modelnet)')
    parser.add_argument('--num-points', default=1024, type=int,
                        metavar='N', help='points in point-cloud (default: 1024)')
    parser.add_argument('--mag', default=0.8, type=float,
                        metavar='T', help='max. mag. of twist-vectors (perturbations) on training (default: 0.8)')
    # C3VD é…å¯¹æ¨¡å¼è®¾ç½®
    parser.add_argument('--pair-mode', default='one_to_one', 
                        choices=['one_to_one', 'scene_reference', 'source_to_source', 'target_to_target', 'all'],
                        help='ç‚¹äº‘é…å¯¹æ¨¡å¼: one_to_one (æ¯ä¸ªæºç‚¹äº‘å¯¹åº”ç‰¹å®šç›®æ ‡ç‚¹äº‘), scene_reference (æ¯ä¸ªåœºæ™¯ä½¿ç”¨ä¸€ä¸ªå…±äº«ç›®æ ‡ç‚¹äº‘), '
                             'source_to_source (æºç‚¹äº‘å’Œæºç‚¹äº‘é…å¯¹), target_to_target (ç›®æ ‡ç‚¹äº‘å’Œç›®æ ‡ç‚¹äº‘é…å¯¹), '
                             'all (åŒ…å«æ‰€æœ‰é…å¯¹æ–¹å¼)')
    parser.add_argument('--reference-name', default=None, type=str,
                        help='åœºæ™¯å‚è€ƒæ¨¡å¼ä¸‹ä½¿ç”¨çš„ç›®æ ‡ç‚¹äº‘åç§°ï¼Œé»˜è®¤ä½¿ç”¨åœºæ™¯ä¸­çš„ç¬¬ä¸€ä¸ªç‚¹äº‘')

    # settings for PointNet
    parser.add_argument('--pointnet', default='tune', type=str, choices=['fixed', 'tune'],
                        help='train pointnet (default: tune)')
    parser.add_argument('--use-tnet', dest='use_tnet', action='store_true',
                        help='flag for setting up PointNet with TNet')
    parser.add_argument('--dim-k', default=1024, type=int,
                        metavar='K', help='dim. of the feature vector (default: 1024)')
    parser.add_argument('--symfn', default='max', choices=['max', 'avg', 'selective'],
                        help='symmetric function (default: max)')
    
    # æ·»åŠ æ¨¡å‹é€‰æ‹©å‚æ•° (ä¸train_classifier.pyä¿æŒä¸€è‡´)
    parser.add_argument('--model-type', default='pointnet', choices=['pointnet', 'attention', 'mamba3d', 'fast_attention', 'cformer'],
                        help='é€‰æ‹©æ¨¡å‹ç±»å‹: pointnetã€attentionã€mamba3dã€fast_attentionæˆ–cformer (é»˜è®¤: pointnet)')
    
    # æ·»åŠ attentionæ¨¡å‹ç‰¹å®šå‚æ•° (ä¸train_classifier.pyä¿æŒä¸€è‡´)
    parser.add_argument('--num-attention-blocks', default=3, type=int,
                        metavar='N', help='attentionæ¨¡å—ä¸­çš„æ³¨æ„åŠ›å—æ•°é‡ (é»˜è®¤: 3)')
    parser.add_argument('--num-heads', default=8, type=int,
                        metavar='N', help='å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•° (é»˜è®¤: 8)')
    
    # æ·»åŠ Mamba3Dæ¨¡å‹ç‰¹å®šå‚æ•°
    parser.add_argument('--num-mamba-blocks', default=3, type=int,
                        metavar='N', help='Mamba3Dæ¨¡å—ä¸­çš„Mambaå—æ•°é‡ (é»˜è®¤: 3)')
    parser.add_argument('--d-state', default=16, type=int,
                        metavar='N', help='MambaçŠ¶æ€ç©ºé—´ç»´åº¦ (é»˜è®¤: 16)')
    parser.add_argument('--expand', default=2, type=float,
                        metavar='N', help='Mambaæ‰©å±•å› å­ (é»˜è®¤: 2)')
    
    # æ·»åŠ å¿«é€Ÿç‚¹æ³¨æ„åŠ›æ¨¡å‹ç‰¹å®šå‚æ•°
    parser.add_argument('--num-fast-attention-blocks', default=2, type=int,
                        metavar='N', help='å¿«é€Ÿç‚¹æ³¨æ„åŠ›æ¨¡å—ä¸­çš„æ³¨æ„åŠ›å—æ•°é‡ (é»˜è®¤: 2)')
    parser.add_argument('--fast-attention-scale', default=1, type=int,
                        metavar='N', help='å¿«é€Ÿç‚¹æ³¨æ„åŠ›æ¨¡å‹çš„è§„æ¨¡ç¼©æ”¾å› å­ (é»˜è®¤: 1, æ›´å¤§å€¼è¡¨ç¤ºæ›´è½»é‡çš„æ¨¡å‹)')
    
    # æ·»åŠ Cformeræ¨¡å‹ç‰¹å®šå‚æ•°
    parser.add_argument('--num-proxy-points', default=8, type=int,
                        metavar='N', help='Cformeræ¨¡å‹ä¸­çš„ä»£ç†ç‚¹æ•°é‡ (é»˜è®¤: 8)')
    parser.add_argument('--num-blocks', default=2, type=int,
                        metavar='N', help='Cformeræ¨¡å‹ä¸­çš„å—æ•°é‡ (é»˜è®¤: 2)')
    
    parser.add_argument('--transfer-from', default='', type=str,
                        metavar='PATH', help='path to pointnet features file')

    # settings for LK
    parser.add_argument('--max-iter', default=10, type=int,
                        metavar='N', help='max-iter on LK. (default: 10)')
    parser.add_argument('--delta', default=1.0e-2, type=float,
                        metavar='D', help='step size for approx. Jacobian (default: 1.0e-2)')
    parser.add_argument('--learn-delta', dest='learn_delta', action='store_true',
                        help='flag for training step size delta')

    # settings for on training
    parser.add_argument('-l', '--logfile', default='', type=str,
                        metavar='LOGNAME', help='path to logfile (default: null (no logging))')
    parser.add_argument('-j', '--workers', default=4, type=int,
                        metavar='N', help='number of data loading workers (default: 4)')
    parser.add_argument('-b', '--batch-size', default=32, type=int,
                        metavar='N', help='mini-batch size (default: 32)')
    parser.add_argument('--epochs', default=200, type=int,
                        metavar='N', help='number of total epochs to run')
    parser.add_argument('--start-epoch', default=0, type=int,
                        metavar='N', help='manual epoch number (useful on restarts)')
    parser.add_argument('--optimizer', default='Adam', choices=['Adam', 'SGD'],
                        metavar='METHOD', help='name of an optimizer (default: Adam)')
    parser.add_argument('--resume', default='', type=str,
                        metavar='PATH', help='path to latest checkpoint (default: null (no-use))')
    parser.add_argument('--pretrained', default='', type=str,
                        metavar='PATH', help='path to pretrained model file (default: null (no-use))')
    parser.add_argument('--device', default='cuda:0', type=str,
                        metavar='DEVICE', help='use CUDA if available')

    # Additional parameters
    parser.add_argument('--verbose', action='store_true',
                        help='Display detailed logs')
    parser.add_argument('--drop-last', action='store_true',
                        help='Drop the last incomplete batch')

    # Scene split parameter
    parser.add_argument('--scene-split', action='store_true',
                        help='Split train and validation sets by scene')
    
    # ä½“ç´ åŒ–ç›¸å…³å‚æ•°
    parser.add_argument('--use-voxelization', action='store_true', default=True,
                        help='å¯ç”¨ä½“ç´ åŒ–é¢„å¤„ç†æ–¹æ³• (é»˜è®¤: True)')
    parser.add_argument('--no-voxelization', dest='use_voxelization', action='store_false',
                        help='ç¦ç”¨ä½“ç´ åŒ–ï¼Œä½¿ç”¨ç®€å•é‡é‡‡æ ·æ–¹æ³•')
    parser.add_argument('--voxel-size', default=0.05, type=float,
                        metavar='SIZE', help='ä½“ç´ å¤§å° (é»˜è®¤: 0.05)')
    parser.add_argument('--voxel-grid-size', default=32, type=int,
                        metavar='SIZE', help='ä½“ç´ ç½‘æ ¼å°ºå¯¸ (é»˜è®¤: 32)')
    parser.add_argument('--max-voxel-points', default=100, type=int,
                        metavar='N', help='æ¯ä¸ªä½“ç´ æœ€å¤§ç‚¹æ•° (é»˜è®¤: 100)')
    parser.add_argument('--max-voxels', default=20000, type=int,
                        metavar='N', help='æœ€å¤§ä½“ç´ æ•°é‡ (é»˜è®¤: 20000)')
    parser.add_argument('--min-voxel-points-ratio', default=0.1, type=float,
                        metavar='RATIO', help='æœ€å°ä½“ç´ ç‚¹æ•°æ¯”ä¾‹é˜ˆå€¼ (é»˜è®¤: 0.1)')
    
    # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å‚æ•° (ä¸train_classifier.pyä¿æŒä¸€è‡´)
    parser.add_argument('--base-lr', default=None, type=float,
                        help='åŸºç¡€å­¦ä¹ ç‡ï¼Œè‡ªåŠ¨è®¾ç½®ä¸ºä¼˜åŒ–å™¨åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--warmup-epochs', default=5, type=int,
                        metavar='N', help='å­¦ä¹ ç‡é¢„çƒ­è½®æ¬¡æ•° (é»˜è®¤: 5)')
    parser.add_argument('--cosine-annealing', action='store_true',
                        help='ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡ç­–ç•¥')

    args = parser.parse_args(argv)
    return args

def main(args):
    # dataset
    trainset, testset = get_datasets(args)

    # é‡ç½®æ—¥å¿—é…ç½®ï¼Œç¡®ä¿æ—¥å¿—æ­£ç¡®å†™å…¥åˆ°æŒ‡å®šæ–‡ä»¶
    if args.logfile:
        # å®Œå…¨é‡ç½®æ—¥å¿—ç³»ç»Ÿ
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)
            
        # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
        logging.basicConfig(
            level=logging.DEBUG,
            format='%(name)s, %(asctime)s, %(message)s',
            filename=args.logfile,
            filemode='w'  # ä½¿ç”¨'w'æ¨¡å¼è¦†ç›–ä»»ä½•å·²å­˜åœ¨çš„æ—¥å¿—æ–‡ä»¶
        )
        
        # é…ç½®æ¨¡å—ç‰¹å®šçš„æ—¥å¿—è®°å½•å™¨
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        
        print(f"æ—¥å¿—å°†å†™å…¥: {args.logfile}")
    
    # training
    act = Action(args)
    run(args, trainset, testset, act)


def run(args, trainset, testset, action):
    # Custom dataset wrapper that handles exceptions
    class DatasetWrapper(torch.utils.data.Dataset):
        """Wrapper for safely loading dataset samples that might cause exceptions.
        
        This wrapper catches exceptions during sample loading and returns None instead,
        which will be filtered out by the custom collate function.
        """
        def __init__(self, dataset):
            self.dataset = dataset

        def __len__(self):
            return len(self.dataset)

        def __getitem__(self, idx):
            try:
                return self.dataset[idx]
            except Exception as e:
                print(f"Warning: Error loading sample at index {idx}: {str(e)}")
                return None

    # è‡ªå®šä¹‰collateå‡½æ•°ï¼Œå¤„ç†Noneå€¼
    def custom_collate_fn(batch):
        """è‡ªå®šä¹‰collateå‡½æ•°ï¼Œè¿‡æ»¤æ‰Noneå€¼å¹¶æ£€æŸ¥æ‰¹æ¬¡å¤§å°"""
        # ç§»é™¤Noneå€¼
        batch = list(filter(lambda x: x is not None, batch))
        
        # æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦ä¸ºç©º
        if len(batch) == 0:
            raise ValueError("All samples in the batch are invalid")
            
        # æ£€æŸ¥æ¯ä¸ªå…ƒç´ æ˜¯å¦åŒ…å«Noneå€¼
        for item in batch:
            if None in item:
                print(f"Warning: Found None in batch item: {item}")
        
        # ä½¿ç”¨é»˜è®¤çš„collateå‡½æ•°å¤„ç†å‰©ä½™æ ·æœ¬
        return torch.utils.data.dataloader.default_collate(batch)
    
    # CUDA availability check
    print(f"\n====== CUDA Availability Check ======")
    if torch.cuda.is_available():
        print(f"CUDA Available: Yes")
        print(f"Number of devices: {torch.cuda.device_count()}")
        print(f"Current device: {torch.cuda.current_device()}")
        print(f"Device name: {torch.cuda.get_device_name(0)}")
    else:
        print(f"CUDA Available: No (training will run on CPU, which will be slow)")
        args.device = 'cpu'
    
    args.device = torch.device(args.device)
    print(f"Using device: {args.device}")
    

    # Dataset statistics
    print("\n====== Detailed Dataset Statistics ======")
    
    # Get original datasets (before wrapping)
    original_trainset = trainset.dataset if isinstance(trainset, DatasetWrapper) else trainset
    original_testset = testset.dataset if isinstance(testset, DatasetWrapper) else testset
    
    if hasattr(original_trainset, 'pairs') and hasattr(original_trainset, 'scenes'):
        print(f"Training set scenes: {len(original_trainset.scenes)}")
        print(f"Training set point cloud pairs: {len(original_trainset.pairs)}")
        print(f"Point cloud pairs distribution per scene:")
        scene_counts = {}
        for scene in original_trainset.pair_scenes:
            scene_counts[scene] = scene_counts.get(scene, 0) + 1
        for scene, count in scene_counts.items():
            print(f"  - {scene}: {count} point cloud pairs")
    
    # Validation set statistics
    if hasattr(original_testset, 'pairs') and hasattr(original_testset, 'scenes'):
        print(f"\nValidation set scenes: {len(original_testset.scenes)}")
        print(f"Validation set point cloud pairs: {len(original_testset.pairs)}")
    
    # Calculate expected batches
    total_samples = len(trainset)
    expected_batches = total_samples // args.batch_size
    if not args.drop_last and total_samples % args.batch_size != 0:
        expected_batches += 1
    
    print(f"\nBatch statistics:")
    print(f"Total samples: {total_samples}")
    print(f"Batch size: {args.batch_size}")
    print(f"Drop last batch: {args.drop_last}")
    print(f"Expected number of batches: {expected_batches}")
    
    # Basic dataset information
    print(f"\n====== Dataset Information ======")
    print(f"Training set: {len(trainset)} samples, Test set: {len(testset)} samples")
    print(f"Batch size: {args.batch_size}, Points per cloud: {args.num_points}, Drop last batch: {args.drop_last}")
    
    # Model initialization and loading
    model = action.create_model()
    if args.pretrained:
        assert os.path.isfile(args.pretrained)
        model.load_state_dict(torch.load(args.pretrained, map_location='cpu'))
    model.to(args.device)
    
    # Confirm model is on correct device
    print(f"\n====== Model Information ======")
    print(f"Number of model parameters: {sum(p.numel() for p in model.parameters())}")
    print(f"Model parameters on CUDA: {next(model.parameters()).is_cuda}")
    if str(args.device) != 'cpu':
        print(f"Current GPU memory usage: {torch.cuda.memory_allocated()/1024**2:.1f}MB")
        print(f"Current GPU memory cached: {torch.cuda.memory_reserved()/1024**2:.1f}MB")

    checkpoint = None
    if args.resume:
        assert os.path.isfile(args.resume)
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
        checkpoint = torch.load(args.resume, map_location='cpu')  # å…ˆåŠ è½½åˆ°CPUï¼Œé¿å…è®¾å¤‡ä¸åŒ¹é…é—®é¢˜
        
        # æ£€æŸ¥checkpointçš„æ ¼å¼
        if isinstance(checkpoint, dict) and 'model' in checkpoint:
            # å®Œæ•´çš„checkpointæ ¼å¼ (åŒ…å«è®­ç»ƒçŠ¶æ€)
            args.start_epoch = checkpoint.get('epoch', 0)
            model.load_state_dict(checkpoint['model'])
            print(f"   - æ£€æŸ¥ç‚¹ç±»å‹: å®Œæ•´è®­ç»ƒçŠ¶æ€")
            print(f"   - æ¢å¤åˆ°epoch: {checkpoint.get('epoch', 0)}")
            print(f"   - ä¹‹å‰æœ€ä½³æŸå¤±: {checkpoint.get('min_loss', 'N/A')}")
            if 'best_epoch' in checkpoint:
                print(f"   - ä¹‹å‰æœ€ä½³epoch: {checkpoint['best_epoch']}")
        else:
            # åªæœ‰æ¨¡å‹æƒé‡çš„æ ¼å¼
            model.load_state_dict(checkpoint)
            args.start_epoch = 0  # ä»epoch 0å¼€å§‹ï¼Œä½†ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            checkpoint = None  # è®¾ç½®ä¸ºNoneï¼Œè¿™æ ·åé¢å°±ä¸ä¼šå°è¯•åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
            print(f"   - æ£€æŸ¥ç‚¹ç±»å‹: ä»…æ¨¡å‹æƒé‡")
            print(f"   - å°†ä»epoch 0å¼€å§‹è®­ç»ƒï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æƒé‡ï¼‰")
            print(f"   - æ³¨æ„: ä¼˜åŒ–å™¨çŠ¶æ€å°†é‡æ–°åˆå§‹åŒ–")

    # Wrap datasets
    trainset = DatasetWrapper(trainset)
    testset = DatasetWrapper(testset)
    
    # Data loaders
    print(f"\n====== Data Loaders ======")
    trainloader = torch.utils.data.DataLoader(
        trainset,
        batch_size=args.batch_size, 
        shuffle=True, 
        num_workers=1,  # å‡å°‘workeræ•°é‡
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    testloader = torch.utils.data.DataLoader(
        testset,
        batch_size=args.batch_size, 
        shuffle=False, 
        num_workers=min(args.workers, 2),
        drop_last=args.drop_last,
        pin_memory=(str(args.device) != 'cpu'),
        collate_fn=custom_collate_fn
    )
    
    print(f"Training batches: {len(trainloader)}, Test batches: {len(testloader)}")
    
    
    # Optimizer
    min_loss = float('inf')
    learnable_params = filter(lambda p: p.requires_grad, model.parameters())
    if args.optimizer == 'Adam':
        optimizer = torch.optim.Adam(learnable_params, lr=0.0001, weight_decay=1e-4, betas=(0.9, 0.999), eps=1e-8)
    else:
        optimizer = torch.optim.SGD(learnable_params, lr=0.001, momentum=0.9, weight_decay=1e-4)

    # æ¢å¤è®­ç»ƒçŠ¶æ€
    best_epoch = 0
    if checkpoint is not None:
        min_loss = checkpoint.get('min_loss', float('inf'))
        best_epoch = checkpoint.get('best_epoch', 0)
        # åªæœ‰å½“checkpointåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€æ—¶æ‰æ¢å¤
        if 'optimizer' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer'])
            print(f"âœ… æˆåŠŸæ¢å¤è®­ç»ƒçŠ¶æ€:")
            print(f"   - å½“å‰æœ€ä½³æŸå¤±: {min_loss}")
            print(f"   - å½“å‰æœ€ä½³epoch: {best_epoch}")
            print(f"   - ä¼˜åŒ–å™¨çŠ¶æ€å·²æ¢å¤")
        else:
            print(f"âš ï¸  éƒ¨åˆ†æ¢å¤è®­ç»ƒçŠ¶æ€:")
            print(f"   - å½“å‰æœ€ä½³æŸå¤±: {min_loss}")
            print(f"   - å½“å‰æœ€ä½³epoch: {best_epoch}")
            print(f"   - ä¼˜åŒ–å™¨çŠ¶æ€å°†é‡æ–°åˆå§‹åŒ–ï¼ˆä½¿ç”¨é»˜è®¤å­¦ä¹ ç‡ï¼‰")
    
    # ä½¿ç”¨æ›´å¼ºçš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
    if args.epochs > 50:
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)
    else:
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.5, patience=5, 
            threshold=0.01, min_lr=1e-6)

    # ========================
    # è°ƒè¯•æ¨¡å¼ï¼šå°è¯•å¤„ç†å•ä¸ªæ‰¹æ¬¡
    # ========================
    print("\n====== è°ƒè¯•æ¨¡å¼ï¼šå•æ‰¹æ¬¡æµ‹è¯• ======")
    try:
        print("è·å–å•ä¸ªæ‰¹æ¬¡æ•°æ®...")
        debug_batch = next(iter(trainloader))
        print(f"æ‰¹æ¬¡æ•°æ®å½¢çŠ¶: {[x.shape for x in debug_batch]}")
        
        print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
        model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        
        try:
            # åœ¨æµ‹è¯•å•ä¸ªæ‰¹æ¬¡æ—¶æ•è·ä»»ä½•é”™è¯¯
            with torch.autograd.detect_anomaly():
                loss, loss_g = action.compute_loss(model, debug_batch, args.device)
                print(f"å‰å‘ä¼ æ’­æˆåŠŸ! loss={loss.item():.4f}, loss_g={loss_g.item():.4f}")
                
                print("\næµ‹è¯•åå‘ä¼ æ’­...")
                optimizer.zero_grad()
                loss.backward()
                print("åå‘ä¼ æ’­æˆåŠŸ!")
                
                print("\næµ‹è¯•å‚æ•°æ›´æ–°...")
                optimizer.step()
                print("å‚æ•°æ›´æ–°æˆåŠŸ!")
                
                print("\nå•æ‰¹æ¬¡æµ‹è¯•å…¨éƒ¨æˆåŠŸ!")
        except Exception as e:
            print(f"å•æ‰¹æ¬¡æµ‹è¯•å¤±è´¥: {e}")
            traceback.print_exc()
    except Exception as e:
        print(f"æ— æ³•è·å–æµ‹è¯•æ‰¹æ¬¡: {e}")
        traceback.print_exc()
    
    print("\næ˜¯å¦ç»§ç»­å®Œæ•´è®­ç»ƒï¼Ÿ(10ç§’åè‡ªåŠ¨ç»§ç»­ï¼ŒæŒ‰Ctrl+Cå¯ä¸­æ–­)")
    try:
        # è®¾ç½®10ç§’æš‚åœï¼Œç”¨æˆ·å¯ä»¥æ£€æŸ¥è¾“å‡ºå¹¶å†³å®šæ˜¯å¦ç»§ç»­
        time.sleep(10)
    except KeyboardInterrupt:
        print("ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
        return
        
    # Training
    print("\n====== Starting Training ======")
    LOGGER.debug('train, begin')
    
    # æ·»åŠ æ•°æ®åŠ è½½å™¨æµ‹è¯•
    print("æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    try:
        print("å°è¯•è·å–ç¬¬ä¸€ä¸ªè®­ç»ƒbatch...")
        test_iter = iter(trainloader)
        first_batch = next(test_iter)
        print(f"ç¬¬ä¸€ä¸ªbatchåŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {[x.shape for x in first_batch]}")
        del test_iter, first_batch  # æ¸…ç†å†…å­˜
    except Exception as e:
        print(f"æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return
    
    total_start_time = time.time()
    for epoch in range(args.start_epoch, args.epochs):
        epoch_start = time.time()
        
        consecutive_nan = 0
        max_consecutive_nan = 20
        last_valid_state = None
        
        # Save state at the beginning of each epoch
        if epoch_start:
            last_valid_state = {
                'model': copy.deepcopy(model.state_dict()),
                'optimizer': copy.deepcopy(optimizer.state_dict())
            }
        
        running_loss, running_info = action.train_1(model, trainloader, optimizer, args.device)
        val_loss, val_info = action.eval_1(model, testloader, args.device)
        
        # Detect consecutive NaNs and recover
        if not isinstance(val_loss, torch.Tensor):
            # If val_loss is a Python float and not a tensor
            if not (isinstance(val_loss, float) and math.isfinite(val_loss)):
                consecutive_nan += 1
                if consecutive_nan >= max_consecutive_nan and last_valid_state is not None:
                    print(f"Warning: Detected {consecutive_nan} consecutive NaN batches, recovering to last valid state")
                    model.load_state_dict(last_valid_state['model'])
                    optimizer.load_state_dict(last_valid_state['optimizer'])
                    consecutive_nan = 0
        else:
            # If val_loss is a tensor
            if not torch.isfinite(val_loss).all():
                consecutive_nan += 1
                if consecutive_nan >= max_consecutive_nan and last_valid_state is not None:
                    print(f"Warning: Detected {consecutive_nan} consecutive NaN batches, recovering to last valid state")
                    model.load_state_dict(last_valid_state['model'])
                    optimizer.load_state_dict(last_valid_state['optimizer'])
                    consecutive_nan = 0
        
        # Update learning rate
        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_loss)
        else:
            scheduler.step()
        
        epoch_time = time.time() - epoch_start
        
        # é¦–å…ˆå®šä¹‰ä¸€ä¸ªå˜é‡æ¥è·Ÿè¸ªbest epochçš„æ•°å€¼
        is_best = val_loss < min_loss
        if is_best:
            best_epoch = epoch + 1  # æ›´æ–°æœ€ä½³epoch
        min_loss = min(val_loss, min_loss)

        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']

        print(f"[Time] Epoch {epoch+1}: {epoch_time:.2f} sec | Loss: {running_loss:.4f} | Validation: {val_loss:.4f}")
        print(f"[Info] Best epoch: {best_epoch}, Current LR: {current_lr:.6f}")
        
        # ä¿®æ”¹æ—¥å¿—è¾“å‡ºï¼Œå¢åŠ best_epochå’Œcurrent_lr
        LOGGER.info('epoch, %04d, %f, %f, %f, %f, %04d, %f', 
                   epoch + 1, running_loss, val_loss, running_info, val_info, best_epoch, current_lr)
        snap = {'epoch': epoch + 1,
                'model': model.state_dict(),
                'min_loss': min_loss,
                'best_epoch': best_epoch,  # ä¿å­˜æœ€ä½³epochä¿¡æ¯
                'optimizer' : optimizer.state_dict(),}
        
        if is_best:
            save_checkpoint(snap, args.outfile, 'snap_best')
            save_checkpoint(model.state_dict(), args.outfile, 'model_best')
            print(f"[Save] Best model saved")

        # Clear cache after each epoch
        if str(args.device) != 'cpu':
            torch.cuda.empty_cache()
            gc.collect()
        
        # Display estimated remaining time
        elapsed = time.time() - total_start_time
        estimated_total = elapsed / (epoch + 1 - args.start_epoch) * (args.epochs - args.start_epoch)
        remaining = estimated_total - elapsed
        print(f"[Progress] {epoch+1}/{args.epochs} epochs | Elapsed: {elapsed/60:.1f} min | Remaining: {remaining/60:.1f} min")

    total_time = time.time() - total_start_time
    print(f"\n====== Training Complete ======")
    print(f"Total training time: {total_time/60:.2f} minutes ({total_time:.2f} seconds)")
    print(f"Average time per epoch: {total_time/(args.epochs-args.start_epoch):.2f} seconds")
    LOGGER.debug('train, end')

def save_checkpoint(state, filename, suffix):
    torch.save(state, '{}_{}.pth'.format(filename, suffix))


class Action:
    def __init__(self, args):
        # PointNetç›¸å…³å‚æ•°
        self.pointnet = args.pointnet # tune or fixed
        self.transfer_from = args.transfer_from
        self.dim_k = args.dim_k
        self.use_tnet = args.use_tnet
        
        # æ·»åŠ æ–°çš„å±æ€§ (ä¸train_classifier.pyä¿æŒä¸€è‡´)
        self.model_type = args.model_type
        self.num_attention_blocks = args.num_attention_blocks
        self.num_heads = args.num_heads
        
        # æ·»åŠ Mamba3Då±æ€§
        self.num_mamba_blocks = args.num_mamba_blocks
        self.d_state = args.d_state
        self.expand = args.expand
        
        # æ·»åŠ å¿«é€Ÿç‚¹æ³¨æ„åŠ›å±æ€§
        self.num_fast_attention_blocks = args.num_fast_attention_blocks
        self.fast_attention_scale = args.fast_attention_scale
        
        # æ·»åŠ Cformerå±æ€§
        self.num_proxy_points = getattr(args, 'num_proxy_points', 8)
        self.num_blocks = getattr(args, 'num_blocks', 2)
        
        # èšåˆå‡½æ•°è®¾ç½® (ä¸train_classifier.pyä¿æŒä¸€è‡´)
        self.sym_fn = None
        if args.model_type == 'attention':
            # ä¸ºattentionæ¨¡å‹è®¾ç½®èšåˆå‡½æ•°
            if args.symfn == 'max':
                self.sym_fn = attention_v1.symfn_max
            elif args.symfn == 'avg':
                self.sym_fn = attention_v1.symfn_avg
            else:
                self.sym_fn = attention_v1.symfn_attention_pool  # attentionç‰¹æœ‰çš„èšåˆ
        elif args.model_type == 'mamba3d':
            # ä¸ºMamba3Dæ¨¡å‹è®¾ç½®èšåˆå‡½æ•°
            if args.symfn == 'max':
                self.sym_fn = mamba3d_v1.symfn_max
            elif args.symfn == 'avg':
                self.sym_fn = mamba3d_v1.symfn_avg
            elif args.symfn == 'selective':
                self.sym_fn = mamba3d_v1.symfn_selective
            else:
                self.sym_fn = mamba3d_v1.symfn_max  # é»˜è®¤ä½¿ç”¨æœ€å¤§æ± åŒ–
        elif args.model_type == 'fast_attention':
            # ä¸ºå¿«é€Ÿç‚¹æ³¨æ„åŠ›æ¨¡å‹è®¾ç½®èšåˆå‡½æ•°
            if args.symfn == 'max':
                self.sym_fn = fast_point_attention.symfn_max
            elif args.symfn == 'avg':
                self.sym_fn = fast_point_attention.symfn_avg
            elif args.symfn == 'selective':
                self.sym_fn = fast_point_attention.symfn_fast_attention_pool  # å¿«é€Ÿæ³¨æ„åŠ›ç‰¹æœ‰çš„èšåˆ
            else:
                self.sym_fn = fast_point_attention.symfn_max  # é»˜è®¤ä½¿ç”¨æœ€å¤§æ± åŒ–
        elif args.model_type == 'cformer':
            # ä¸ºCformeræ¨¡å‹è®¾ç½®èšåˆå‡½æ•°
            if args.symfn == 'max':
                self.sym_fn = cformer.symfn_max
            elif args.symfn == 'avg':
                self.sym_fn = cformer.symfn_avg
            elif args.symfn == 'cd_pool':
                self.sym_fn = cformer.symfn_cd_pool
            else:
                self.sym_fn = cformer.symfn_max  # é»˜è®¤ä½¿ç”¨æœ€å¤§æ± åŒ–
        else:
            # ä¸ºpointnetæ¨¡å‹è®¾ç½®èšåˆå‡½æ•°
            if args.symfn == 'max':
                self.sym_fn = ptlk.pointnet.symfn_max
            elif args.symfn == 'avg':
                self.sym_fn = ptlk.pointnet.symfn_avg
                
        # LKå‚æ•°
        self.delta = args.delta
        self.learn_delta = args.learn_delta
        self.max_iter = args.max_iter
        self.xtol = 1.0e-7
        self.p0_zero_mean = True
        self.p1_zero_mean = True

        self._loss_type = 1 # see. self.compute_loss()

    def create_model(self):
        if self.model_type == 'attention':
            # åˆ›å»ºattentionæ¨¡å‹
            ptnet = attention_v1.AttentionNet_features(
                dim_k=self.dim_k, 
                sym_fn=self.sym_fn,
                scale=1,
                num_attention_blocks=self.num_attention_blocks,
                num_heads=self.num_heads
            )
            # æ”¯æŒä»attentionåˆ†ç±»å™¨åŠ è½½é¢„è®­ç»ƒæƒé‡
            if self.transfer_from and os.path.isfile(self.transfer_from):
                try:
                    pretrained_dict = torch.load(self.transfer_from, map_location='cpu')
                    ptnet.load_state_dict(pretrained_dict)
                    print(f"æˆåŠŸåŠ è½½attentioné¢„è®­ç»ƒæƒé‡: {self.transfer_from}")
                except Exception as e:
                    print(f"åŠ è½½attentioné¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                    print("ç»§ç»­ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        elif self.model_type == 'mamba3d':
            # åˆ›å»ºMamba3Dæ¨¡å‹
            ptnet = mamba3d_v1.Mamba3D_features(
                dim_k=self.dim_k, 
                sym_fn=self.sym_fn,
                scale=1,
                num_mamba_blocks=self.num_mamba_blocks,
                d_state=self.d_state,
                expand=self.expand
            )
            # æ”¯æŒä»Mamba3Dåˆ†ç±»å™¨åŠ è½½é¢„è®­ç»ƒæƒé‡
            if self.transfer_from and os.path.isfile(self.transfer_from):
                try:
                    pretrained_dict = torch.load(self.transfer_from, map_location='cpu')
                    ptnet.load_state_dict(pretrained_dict)
                    print(f"æˆåŠŸåŠ è½½Mamba3Dé¢„è®­ç»ƒæƒé‡: {self.transfer_from}")
                except Exception as e:
                    print(f"åŠ è½½Mamba3Dé¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                    print("ç»§ç»­ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        elif self.model_type == 'fast_attention':
            # åˆ›å»ºå¿«é€Ÿç‚¹æ³¨æ„åŠ›æ¨¡å‹
            ptnet = fast_point_attention.FastPointAttention_features(
                dim_k=self.dim_k, 
                sym_fn=self.sym_fn,
                scale=self.fast_attention_scale,
                num_attention_blocks=self.num_fast_attention_blocks
            )
            # æ”¯æŒä»å¿«é€Ÿç‚¹æ³¨æ„åŠ›åˆ†ç±»å™¨åŠ è½½é¢„è®­ç»ƒæƒé‡
            if self.transfer_from and os.path.isfile(self.transfer_from):
                try:
                    pretrained_dict = torch.load(self.transfer_from, map_location='cpu')
                    ptnet.load_state_dict(pretrained_dict)
                    print(f"æˆåŠŸåŠ è½½å¿«é€Ÿç‚¹æ³¨æ„åŠ›é¢„è®­ç»ƒæƒé‡: {self.transfer_from}")
                except Exception as e:
                    print(f"åŠ è½½å¿«é€Ÿç‚¹æ³¨æ„åŠ›é¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                    print("ç»§ç»­ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        elif self.model_type == 'cformer':
            # åˆ›å»ºCformeræ¨¡å‹
            ptnet = cformer.CFormer_features(
                dim_k=self.dim_k, 
                sym_fn=self.sym_fn,
                scale=1,
                num_proxy_points=self.num_proxy_points,
                num_blocks=self.num_blocks
            )
            # æ”¯æŒä»Cformeråˆ†ç±»å™¨åŠ è½½é¢„è®­ç»ƒæƒé‡
            if self.transfer_from and os.path.isfile(self.transfer_from):
                try:
                    pretrained_dict = torch.load(self.transfer_from, map_location='cpu')
                    ptnet.load_state_dict(pretrained_dict)
                    print(f"æˆåŠŸåŠ è½½Cformeré¢„è®­ç»ƒæƒé‡: {self.transfer_from}")
                except Exception as e:
                    print(f"åŠ è½½Cformeré¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                    print("ç»§ç»­ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        else:
            # åˆ›å»ºåŸå§‹pointnetæ¨¡å‹
            ptnet = ptlk.pointnet.PointNet_features(self.dim_k, sym_fn=self.sym_fn)
            if self.transfer_from and os.path.isfile(self.transfer_from):
                try:
                    pretrained_dict = torch.load(self.transfer_from, map_location='cpu')
                    ptnet.load_state_dict(pretrained_dict)
                    print(f"æˆåŠŸåŠ è½½PointNeté¢„è®­ç»ƒæƒé‡: {self.transfer_from}")
                except Exception as e:
                    print(f"åŠ è½½PointNeté¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                    print("ç»§ç»­ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        
        if self.pointnet == 'tune':
            pass
        elif self.pointnet == 'fixed':
            for param in ptnet.parameters():
                param.requires_grad_(False)
                
        return ptlk.pointlk.PointLK(ptnet, self.delta, self.learn_delta)

    def train_1(self, model, trainloader, optimizer, device):
        model.train()
        vloss = 0.0
        gloss = 0.0
        count = 0
        nan_batch_count = 0
        nan_loss_count = 0
        nan_grad_count = 0
        
        batch_times = []
        data_times = []
        forward_times = []
        backward_times = []
        
        print("=========== è®­ç»ƒå¾ªç¯å¼€å§‹ ===========")
        print("æ€»æ‰¹æ¬¡æ•°: {}".format(len(trainloader)))
        print("è®¾å¤‡: {}".format(device))
        print("å½“å‰CUDAå†…å­˜: {:.1f}MB".format(torch.cuda.memory_allocated()/1024**2 if str(device) != 'cpu' else 0))
        
        batch_start = time.time()
        
        for i, data in enumerate(trainloader):
            print("\n----- å¼€å§‹å¤„ç†æ‰¹æ¬¡ {}/{} -----".format(i+1, len(trainloader)))
            data_time = time.time() - batch_start
            data_times.append(data_time)
            print("æ•°æ®åŠ è½½æ—¶é—´: {:.4f}ç§’".format(data_time))
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            if len(data) != 3:
                print("è­¦å‘Š: æ‰¹æ¬¡æ•°æ®ä¸å®Œæ•´ï¼Œåº”æœ‰3ä¸ªå…ƒç´ ï¼Œå®é™…æœ‰{}ä¸ª".format(len(data)))
                batch_start = time.time()
                continue
                
            print("æ•°æ®å½¢çŠ¶: {}".format([x.shape for x in data]))
            print("æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«NaN: p0={}, p1={}, igt={}".format(
                torch.isnan(data[0]).any(), torch.isnan(data[1]).any(), torch.isnan(data[2]).any()))
            
            # Forward pass
            print("å¼€å§‹å‰å‘ä¼ æ’­...")
            forward_start = time.time()
            
            try:
                loss, loss_g = self.compute_loss(model, data, device)
                print("æŸå¤±è®¡ç®—å®Œæˆ: loss={:.4f}, loss_g={:.4f}".format(loss.item(), loss_g.item()))
            except Exception as e:
                print("å‰å‘ä¼ æ’­æˆ–æŸå¤±è®¡ç®—å‡ºé”™: {}".format(e))
                traceback.print_exc()
                nan_batch_count += 1
                batch_start = time.time()
                continue
            
            # Check if loss is NaN, if so skip this batch
            if not torch.isfinite(loss) or not torch.isfinite(loss_g):
                print(f"è­¦å‘Š: æ‰¹æ¬¡ {i} æŸå¤±å€¼éæœ‰é™ {loss.item() if torch.isfinite(loss) else 'NaN'}/{loss_g.item() if torch.isfinite(loss_g) else 'NaN'}, è·³è¿‡")
                nan_loss_count += 1
                nan_batch_count += 1
                batch_start = time.time()
                continue
                
            if str(device) != 'cpu':
                torch.cuda.synchronize()
            forward_time = time.time() - forward_start
            forward_times.append(forward_time)
            print("å‰å‘ä¼ æ’­æ—¶é—´: {:.4f}ç§’".format(forward_time))
            
            # Backward pass
            print("å¼€å§‹åå‘ä¼ æ’­...")
            backward_start = time.time()
            
            try:
                optimizer.zero_grad()
                print("æ¢¯åº¦å·²æ¸…é›¶")
                
                loss.backward()
                print("åå‘ä¼ æ’­å®Œæˆ")
                
                # Stronger gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)
                print("æ¢¯åº¦è£å‰ªå®Œæˆ")
            except Exception as e:
                print("åå‘ä¼ æ’­å‡ºé”™: {}".format(e))
                traceback.print_exc()
                nan_batch_count += 1
                batch_start = time.time()
                continue
            
            # Check if gradients contain NaN or Inf values
            do_step = True
            grad_check_start = time.time()
            for name, param in model.named_parameters():
                if param.grad is not None:
                    if (1 - torch.isfinite(param.grad).long()).sum() > 0:
                        do_step = False
                        print(f"è­¦å‘Š: å‚æ•° {name} çš„æ¢¯åº¦åŒ…å«NaN/Infå€¼")
                        nan_grad_count += 1
                        break
            print("æ¢¯åº¦æ£€æŸ¥è€—æ—¶: {:.4f}ç§’".format(time.time() - grad_check_start))
            
            # Only update parameters when gradients are normal
            if do_step:
                print("æ›´æ–°å‚æ•°...")
                try:
                    optimizer.step()
                    print("å‚æ•°æ›´æ–°å®Œæˆ")
                except Exception as e:
                    print("å‚æ•°æ›´æ–°å‡ºé”™: {}".format(e))
                    traceback.print_exc()
                    nan_batch_count += 1
                    batch_start = time.time()
                    continue
            else:
                # If gradients are abnormal, don't include in average loss
                print("ç”±äºæ¢¯åº¦é—®é¢˜è·³è¿‡å‚æ•°æ›´æ–°")
                nan_batch_count += 1
                batch_start = time.time()
                continue
                
            if str(device) != 'cpu':
                torch.cuda.synchronize()
                print("å½“å‰CUDAå†…å­˜: {:.1f}MB".format(torch.cuda.memory_allocated()/1024**2))
                
            backward_time = time.time() - backward_start
            backward_times.append(backward_time)
            print("åå‘ä¼ æ’­æ—¶é—´: {:.4f}ç§’".format(backward_time))

            # Only normal batches count toward total loss and count
            vloss += loss.item()
            gloss += loss_g.item()
            count += 1
            
            # Record total batch time
            batch_time = time.time() - batch_start
            batch_times.append(batch_time)
            
            print(f"----- æ‰¹æ¬¡ {i+1}/{len(trainloader)} å®Œæˆ | æŸå¤±: {loss.item():.4f} | ç”¨æ—¶: {batch_time:.4f}ç§’ -----")
            
            # Display progress every 5 batches
            if i % 5 == 0:
                if str(device) != 'cpu':
                    mem_used = torch.cuda.memory_allocated()/1024**2
                    mem_total = torch.cuda.get_device_properties(0).total_memory/1024**2
                    print(f"æ‰¹æ¬¡ {i+1}/{len(trainloader)} | æŸå¤±: {loss.item():.4f} | GPUå†…å­˜: {mem_used:.1f}/{mem_total:.1f}MB | ç”¨æ—¶: {batch_time:.4f} ç§’")
                else:
                    print(f"æ‰¹æ¬¡ {i+1}/{len(trainloader)} | æŸå¤±: {loss.item():.4f} | ç”¨æ—¶: {batch_time:.4f} ç§’")
            
            batch_start = time.time()
            
            # å¢åŠ æ£€æŸ¥ç‚¹ï¼Œæ¯10ä¸ªæ‰¹æ¬¡ä¿å­˜ä¸€æ¬¡è®­ç»ƒçŠ¶æ€ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜
            if i > 0 and i % 10 == 0:
                print(f"ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹ (æ‰¹æ¬¡ {i+1}/{len(trainloader)})")
                temp_checkpoint = {
                    'epoch': 0,  # é¦–ä¸ªepoch
                    'batch': i,
                    'model': model.state_dict(),
                    'optimizer': optimizer.state_dict(),
                }
                torch.save(temp_checkpoint, '/SAN/medic/MRpcr/results/mamba3d_c3vd/mamba3d_pointlk_temp_checkpoint.pth')

        # Display NaN batch statistics
        if nan_batch_count > 0:
            print(f"\nè­¦å‘Š: {nan_batch_count} ä¸ªæ‰¹æ¬¡è¢«è·³è¿‡ ({nan_batch_count/len(trainloader)*100:.2f}%)")
            print(f"- NaNæŸå¤±æ‰¹æ¬¡: {nan_loss_count}")
            print(f"- NaNæ¢¯åº¦æ‰¹æ¬¡: {nan_grad_count}")
            
        # Safely calculate averages
        ave_vloss = float(vloss)/count if count > 0 else float('inf')
        ave_gloss = float(gloss)/count if count > 0 else float('inf')
        
        # Calculate average times
        avg_batch = sum(batch_times) / len(batch_times) if batch_times else 0
        avg_data = sum(data_times) / len(data_times) if data_times else 0
        avg_forward = sum(forward_times) / len(forward_times) if forward_times else 0
        avg_backward = sum(backward_times) / len(backward_times) if backward_times else 0
        
        print(f"\næ€§èƒ½ç»Ÿè®¡:")
        print(f"æœ‰æ•ˆæ‰¹æ¬¡: {count}/{len(trainloader)} ({count/len(trainloader)*100:.2f}%)")
        print(f"å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_batch:.4f} ç§’ = æ•°æ®åŠ è½½: {avg_data:.4f} ç§’ + å‰å‘ä¼ æ’­: {avg_forward:.4f} ç§’ + åå‘ä¼ æ’­: {avg_backward:.4f} ç§’")
        print(f"è®­ç»ƒç»“æœ: æŸå¤±={ave_vloss:.4f}, ç‰¹å¾æŸå¤±={ave_gloss:.4f}")
        
        return ave_vloss, ave_gloss

    def eval_1(self, model, testloader, device):
        model.eval()
        vloss = 0.0
        gloss = 0.0
        count = 0
        nan_count = 0
        
        print("\n====== Starting Validation ======")
        
        with torch.no_grad():
            for i, data in enumerate(testloader):
                try:
                    loss, loss_g = self.compute_loss(model, data, device)
                    
                    # Skip NaN losses
                    if not torch.isfinite(loss) or not torch.isfinite(loss_g):
                        print(f"Validation batch {i}: Loss has non-finite values, skipping")
                        nan_count += 1
                        continue

                    vloss += loss.item()
                    gloss += loss_g.item()
                    count += 1
                    
                    # Display progress every 10 batches
                    if i % 10 == 0:
                        print(f"Validation batch {i}/{len(testloader)} | Loss: {loss.item():.4f}")
                        
                except Exception as e:
                    print(f"Error processing validation batch {i}: {e}")
                    nan_count += 1
                    continue

        # Safely calculate averages
        if count > 0:
            ave_vloss = float(vloss)/count
            ave_gloss = float(gloss)/count
        else:
            print("Warning: All validation batches failed!")
            ave_vloss = 1e5  # Use a large value instead of inf
            ave_gloss = 1e5
        
        print(f"\nValidation statistics:")
        print(f"Valid batches: {count}/{len(testloader)} ({count/len(testloader)*100:.2f}%)")
        print(f"Validation results: Loss={ave_vloss:.4f}, Feature loss={ave_gloss:.4f}")
        
        if nan_count > 0:
            print(f"Evaluation: {nan_count} batches had NaN values ({nan_count/len(testloader)*100:.2f}%)")
            
        return ave_vloss, ave_gloss

    def compute_loss(self, model, data, device):
        print("====== å¼€å§‹è®¡ç®—æŸå¤± ======")
        p0, p1, igt = data
        # å…‹éš†å¼ é‡ä»¥é¿å…å†…å­˜æ“ä½œé—®é¢˜
        print("å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡: {}".format(device))
        p0 = p0.clone().to(device) # template
        p1 = p1.clone().to(device) # source
        igt = igt.clone().to(device) # igt: p0 -> p1
        
        print("ç‚¹äº‘å½¢çŠ¶: p0={}, p1={}, igt={}".format(p0.shape, p1.shape, igt.shape))
        
        # Check input point clouds
        if not torch.isfinite(p0).all() or not torch.isfinite(p1).all():
            print("è­¦å‘Š: è¾“å…¥ç‚¹äº‘åŒ…å«NaNæˆ–Infå€¼ï¼Œå°è¯•ä¿®å¤")
            # Replace NaN and Inf with 0
            p0 = torch.nan_to_num(p0, nan=0.0, posinf=1.0, neginf=-1.0)
            p1 = torch.nan_to_num(p1, nan=0.0, posinf=1.0, neginf=-1.0)
            print("ä¿®å¤åæ£€æŸ¥: p0 finite={}, p1 finite={}".format(
                torch.isfinite(p0).all(), torch.isfinite(p1).all()))
        
        try:
            # ç¡®ä¿åœ¨è°ƒç”¨å‰æ­£ç¡®å…‹éš†å’Œæ•°æ®è¿ç§»
            print("å‡†å¤‡è°ƒç”¨do_forward...")
            p0_clone = p0.clone().detach().to(device)
            p1_clone = p1.clone().detach().to(device)
            print("å‚æ•°æ£€æŸ¥: max_iter={}, xtol={}, p0_zero_mean={}, p1_zero_mean={}".format(
                self.max_iter, self.xtol, self.p0_zero_mean, self.p1_zero_mean))
            
            # æ‰“å°ç‚¹äº‘çš„ç»Ÿè®¡ä¿¡æ¯
            print("ç‚¹äº‘ç»Ÿè®¡: p0_mean={:.4f}, p0_std={:.4f}, p1_mean={:.4f}, p1_std={:.4f}".format(
                p0_clone.mean().item(), p0_clone.std().item(), 
                p1_clone.mean().item(), p1_clone.std().item()))
            
            print("å¼€å§‹è°ƒç”¨do_forward...")
            r_start_time = time.time()
            r = ptlk.pointlk.PointLK.do_forward(model, p0_clone, p1_clone, self.max_iter, self.xtol,
                                             self.p0_zero_mean, self.p1_zero_mean)
            r_time = time.time() - r_start_time
            print("do_forwardå®Œæˆï¼Œè€—æ—¶: {:.4f}ç§’".format(r_time))
            print("rå½¢çŠ¶: {}ï¼Œrç»Ÿè®¡: mean={:.4f}, std={:.4f}, min={:.4f}, max={:.4f}, åŒ…å«NaN={}".format(
                r.shape, r.mean().item(), r.std().item(), r.min().item(), r.max().item(), torch.isnan(r).any()))
            
            print("è·å–å˜æ¢çŸ©é˜µest_g...")
            est_g = model.g
            print("est_gå½¢çŠ¶: {}ï¼ŒåŒ…å«NaN={}".format(est_g.shape, torch.isnan(est_g).any()))

            # Add numerical check
            if not torch.isfinite(est_g).all():
                print("è­¦å‘Š: å˜æ¢çŸ©é˜µåŒ…å«éæœ‰é™å€¼")
                print("est_gè¯¦ç»†ä¿¡æ¯:")
                print(est_g)
                return torch.tensor(float('nan'), device=device), torch.tensor(float('nan'), device=device)
            
            print("è®¡ç®—loss_g...")
            loss_g_start = time.time()
            loss_g = ptlk.pointlk.PointLK.comp(est_g, igt)
            print("loss_gè®¡ç®—å®Œæˆ: {:.4f}ï¼Œè€—æ—¶: {:.4f}ç§’".format(loss_g.item(), time.time() - loss_g_start))
            
            # Add loss value limiting
            if loss_g > 1e5:
                print(f"è­¦å‘Š: Loss g è¿‡å¤§ ({loss_g.item()})ï¼Œé™åˆ¶ä¸º 1e5")
                loss_g = torch.clamp(loss_g, max=1e5)

            print("è®¡ç®—æœ€ç»ˆæŸå¤±...")
            if self._loss_type == 0:
                loss_r = ptlk.pointlk.PointLK.rsq(r)
                loss = loss_r
                print("æŸå¤±ç±»å‹ 0: loss_r={:.4f}, æœ€ç»ˆloss={:.4f}".format(loss_r.item(), loss.item()))
            elif self._loss_type == 1:
                loss_r = ptlk.pointlk.PointLK.rsq(r)
                # Set loss scale to prevent numerical issues
                loss = loss_r + loss_g * 0.1  # Reduce loss_g weight
                print("æŸå¤±ç±»å‹ 1: loss_r={:.4f}, loss_g={:.4f}, æœ€ç»ˆloss={:.4f}".format(
                    loss_r.item(), loss_g.item()*0.1, loss.item()))
            elif self._loss_type == 2:
                pr = model.prev_r
                if pr is not None:
                    loss_r = ptlk.pointlk.PointLK.rsq(r - pr)
                    print("ä½¿ç”¨ä¸Šä¸€ä¸ªr: prå½¢çŠ¶={}".format(pr.shape))
                else:
                    loss_r = ptlk.pointlk.PointLK.rsq(r)
                    print("æ²¡æœ‰ä¸Šä¸€ä¸ªr")
                loss = loss_r + loss_g * 0.1  # Reduce loss_g weight
                print("æŸå¤±ç±»å‹ 2: loss_r={:.4f}, loss_g={:.4f}, æœ€ç»ˆloss={:.4f}".format(
                    loss_r.item(), loss_g.item()*0.1, loss.item()))
            else:
                loss = loss_g
                print("æŸå¤±ç±»å‹ å…¶ä»–: ç›´æ¥ä½¿ç”¨loss_g={:.4f}".format(loss_g.item()))
            
            # Final check
            if not torch.isfinite(loss):
                print(f"è­¦å‘Š: æœ€ç»ˆæŸå¤±æœ‰éæœ‰é™å€¼ {loss}")
                return torch.tensor(1e5, device=device), torch.tensor(1e5, device=device)
            
            print("====== æŸå¤±è®¡ç®—å®Œæˆ ======")
            return loss, loss_g
        
        except Exception as e:
            print(f"æŸå¤±è®¡ç®—é”™è¯¯: {e}")
            traceback.print_exc()
            return torch.tensor(float('nan'), device=device), torch.tensor(float('nan'), device=device)


class ShapeNet2_transform_coordinate:
    def __init__(self):
        pass
    def __call__(self, mesh):
        return mesh.clone().rot_x()

def get_datasets(args):

    cinfo = None
    if args.categoryfile:
        #categories = numpy.loadtxt(args.categoryfile, dtype=str, delimiter="\n").tolist()
        categories = [line.rstrip('\n') for line in open(args.categoryfile)]
        categories.sort()
        c_to_idx = {categories[i]: i for i in range(len(categories))}
        cinfo = (categories, c_to_idx)

    if args.dataset_type == 'modelnet':
        transform = torchvision.transforms.Compose([\
                ptlk.data.transforms.Mesh2Points(),\
                ptlk.data.transforms.OnUnitCube(),\
                ptlk.data.transforms.Resampler(args.num_points),\
            ])

        traindata = ptlk.data.datasets.ModelNet(args.dataset_path, train=1, transform=transform, classinfo=cinfo)
        testdata = ptlk.data.datasets.ModelNet(args.dataset_path, train=0, transform=transform, classinfo=cinfo)

        mag_randomly = True
        trainset = ptlk.data.datasets.CADset4tracking(traindata,\
                        ptlk.data.transforms.RandomTransformSE3(args.mag, mag_randomly))
        testset = ptlk.data.datasets.CADset4tracking(testdata,\
                        ptlk.data.transforms.RandomTransformSE3(args.mag, mag_randomly))

    elif args.dataset_type == 'shapenet2':
        transform = torchvision.transforms.Compose([\
                ShapeNet2_transform_coordinate(),\
                ptlk.data.transforms.Mesh2Points(),\
                ptlk.data.transforms.OnUnitCube(),\
                ptlk.data.transforms.Resampler(args.num_points),\
            ])

        dataset = ptlk.data.datasets.ShapeNet2(args.dataset_path, transform=transform, classinfo=cinfo)
        traindata, testdata = dataset.split(0.8)

        mag_randomly = True
        trainset = ptlk.data.datasets.CADset4tracking(traindata,\
                        ptlk.data.transforms.RandomTransformSE3(args.mag, mag_randomly))
        testset = ptlk.data.datasets.CADset4tracking(testdata,\
                        ptlk.data.transforms.RandomTransformSE3(args.mag, mag_randomly))

    elif args.dataset_type == 'c3vd':
        # ç§»é™¤transformï¼Œå› ä¸ºC3VDä¸å†éœ€è¦
        # transform = torchvision.transforms.Compose([
        #     # ç§»é™¤å½’ä¸€åŒ–ï¼Œå› ä¸ºC3VDä¸å†éœ€è¦
        #     # ptlk.data.transforms.OnUnitCube(),
        # ])
        
        # é…ç½®ä½“ç´ åŒ–å‚æ•°
        use_voxelization = getattr(args, 'use_voxelization', True)
        voxel_config = None
        if use_voxelization:
            # åˆ›å»ºä½“ç´ åŒ–é…ç½®
            voxel_config = ptlk.data.datasets.VoxelizationConfig(
                voxel_size=getattr(args, 'voxel_size', 1),
                voxel_grid_size=getattr(args, 'voxel_grid_size', 32),
                max_voxel_points=getattr(args, 'max_voxel_points', 100),
                max_voxels=getattr(args, 'max_voxels', 20000),
                min_voxel_points_ratio=getattr(args, 'min_voxel_points_ratio', 0.1)
            )
            print(f"ä½“ç´ åŒ–é…ç½®: ä½“ç´ å¤§å°={voxel_config.voxel_size}, ç½‘æ ¼å°ºå¯¸={voxel_config.voxel_grid_size}")
        else:
            print("ä½¿ç”¨ç®€å•é‡é‡‡æ ·æ–¹æ³•")
        
        # Create C3VD dataset
        c3vd_dataset = ptlk.data.datasets.C3VDDataset(
            source_root=os.path.join(args.dataset_path, 'C3VD_ply_source'),
            target_root=os.path.join(args.dataset_path, 'visible_point_cloud_ply_depth'),
            transform=None, # ç§»é™¤transform
            pair_mode=getattr(args, 'pair_mode', 'one_to_one'),
            reference_name=getattr(args, 'reference_name', None)
        )
        
        # Split based on scene or randomly
        if args.scene_split:
            # Get all scenes
            all_scenes = []
            source_root = os.path.join(args.dataset_path, 'C3VD_ply_source')
            for scene_dir in glob.glob(os.path.join(source_root, "*")):
                if os.path.isdir(scene_dir):
                    all_scenes.append(os.path.basename(scene_dir))
            
            # Randomly select 4 scenes for validation (fixed random seed to ensure consistency with classifier)
            random.seed(42)
            test_scenes = random.sample(all_scenes, 4)
            train_scenes = [scene for scene in all_scenes if scene not in test_scenes]
            
            print(f"Training scenes ({len(train_scenes)}): {train_scenes}")
            print(f"Validation scenes ({len(test_scenes)}): {test_scenes}")
            
            # Split data by scene
            train_indices = []
            test_indices = []
            
            for idx, (source_file, target_file) in enumerate(c3vd_dataset.pairs):
                # Extract scene name
                scene_name = None
                for scene in all_scenes:
                    if f"/{scene}/" in source_file:
                        scene_name = scene
                        break
                
                if scene_name in train_scenes:
                    train_indices.append(idx)
                elif scene_name in test_scenes:
                    test_indices.append(idx)
            
            # Create subsets
            traindata = torch.utils.data.Subset(c3vd_dataset, train_indices)
            testdata = torch.utils.data.Subset(c3vd_dataset, test_indices)
            
            print(f"Scene-based split: Training samples: {len(traindata)}, Validation samples: {len(testdata)}")
        else:
            # Original random split method
            dataset_size = len(c3vd_dataset)
            train_size = int(dataset_size * 0.8)
            test_size = dataset_size - train_size
            traindata, testdata = torch.utils.data.random_split(c3vd_dataset, [train_size, test_size])
            print(f"Random split: Training samples: {len(traindata)}, Validation samples: {len(testdata)}")
        
        # Create tracking datasets for training and testing with voxelization support
        mag_randomly = True
        trainset = ptlk.data.datasets.C3VDset4tracking(
            traindata, 
            ptlk.data.transforms.RandomTransformSE3(args.mag, mag_randomly),
            num_points=args.num_points,
            use_voxelization=use_voxelization,
            voxel_config=voxel_config
        )
        testset = ptlk.data.datasets.C3VDset4tracking(
            testdata, 
            ptlk.data.transforms.RandomTransformSE3(args.mag, mag_randomly),
            num_points=args.num_points,
            use_voxelization=use_voxelization,
            voxel_config=voxel_config
        )
    
    return trainset, testset


if __name__ == '__main__':
    ARGS = options()

    logging.basicConfig(
        level=logging.DEBUG,
        format='%(levelname)s:%(name)s, %(asctime)s, %(message)s',
        filename=ARGS.logfile)
    LOGGER.debug('Training (PID=%d), %s', os.getpid(), ARGS)

    main(ARGS)
    LOGGER.debug('done (PID=%d)', os.getpid())

#EOF