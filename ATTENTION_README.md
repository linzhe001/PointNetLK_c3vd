# PointNetLK with Attention Embedding - å®Œæ•´å®ç°æ–‡æ¡£

## ğŸš€ æ¦‚è¿°

æœ¬é¡¹ç›®æˆåŠŸå¼€å‘å¹¶é›†æˆäº†åŸºäºTransformeræ³¨æ„åŠ›æœºåˆ¶çš„ç‚¹äº‘ç‰¹å¾æå–å™¨ï¼Œä¸“ä¸ºç‚¹äº‘é…å‡†å’Œåˆ†ç±»ä»»åŠ¡è®¾è®¡ã€‚AttentionNetæ¨¡å—å®Œå…¨æ›¿æ¢åŸå§‹PointNetï¼Œæä¾›æ›´å¼ºå¤§çš„ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå®Œå…¨çš„APIå…¼å®¹æ€§ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ§  ä¸»è¦æŠ€æœ¯ä¼˜åŠ¿
- **ğŸ”¥ å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶**: æ•è·ç‚¹ä¸ç‚¹ä¹‹é—´çš„é•¿è·ç¦»ä¾èµ–å…³ç³»
- **ğŸŒŸ 3Dä½ç½®ç¼–ç **: æ˜¾å¼ä¿ç•™å’Œåˆ©ç”¨ç‚¹äº‘çš„ä¸‰ç»´ç©ºé—´ç»“æ„ä¿¡æ¯
- **âš¡ æ®‹å·®è¿æ¥**: æé«˜æ·±å±‚ç½‘ç»œçš„è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦
- **ğŸ¯ å±‚å½’ä¸€åŒ–**: åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹å¹¶æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- **ğŸ”„ ç½®æ¢ä¸å˜æ€§**: å¤©ç„¶é€‚åº”ç‚¹äº‘æ•°æ®çš„æ— åºç‰¹æ€§
- **ğŸ›ï¸ çµæ´»é…ç½®**: æ”¯æŒå¤šç§æ¶æ„é…ç½®å’Œèšåˆç­–ç•¥
- **ğŸ”— å®Œå…¨å…¼å®¹**: ä¸åŸå§‹PointNetä¿æŒ100%çš„APIå…¼å®¹æ€§

## ğŸ“‹ æ–‡ä»¶ç»“æ„

```
PointNetLK_c3vd/
â”œâ”€â”€ ptlk/
â”‚   â”œâ”€â”€ attention_v1.py          # ğŸ§  Attentionæ¨¡å—æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ pointlk.py               # ğŸ”— PointLKç®—æ³• (æ”¯æŒattention)
â”‚   â””â”€â”€ pointnet.py              # ğŸ“¦ åŸå§‹PointNetå®ç°
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train_pointlk.py         # ğŸš‚ ç‚¹äº‘é…å‡†è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ train_classifier.py     # ğŸ·ï¸ ç‚¹äº‘åˆ†ç±»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ ATTENTION_README.md           # ğŸ“– æœ¬æ–‡æ¡£
â””â”€â”€ test_attention.py            # ğŸ§ª åŠŸèƒ½æµ‹è¯•è„šæœ¬
```

## ğŸ—ï¸ è¯¦ç»†æ¶æ„è®¾è®¡

### 1. æ ¸å¿ƒæ¨¡å—å±‚æ¬¡ç»“æ„

```
AttentionNet_features (ä¸»ç‰¹å¾æå–å™¨)
â”œâ”€â”€ input_projection: Linear(3 â†’ d_model)        # è¾“å…¥åµŒå…¥å±‚
â”œâ”€â”€ pos_encoding: PositionalEncoding3D           # ä½ç½®ç¼–ç 
â”œâ”€â”€ attention_blocks: ModuleList[AttentionBlock] # å¤šå±‚æ³¨æ„åŠ›å—
â”‚   â””â”€â”€ AttentionBlock (é‡å¤Næ¬¡)
â”‚       â”œâ”€â”€ self_attention: MultiHeadSelfAttention
â”‚       â””â”€â”€ feed_forward: FeedForwardNetwork
â”œâ”€â”€ feature_transform: MLPNet                    # ç‰¹å¾å˜æ¢å±‚
â””â”€â”€ sy: Aggregation Function                     # å…¨å±€èšåˆå‡½æ•°
```

### 2. MultiHeadSelfAttention å®ç°ç»†èŠ‚

```python
class MultiHeadSelfAttention(nn.Module):
    """å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å®Œæ•´å®ç°
    
    æ•°å­¦åŸç†:
    - Query: Q = XW_q, Key: K = XW_k, Value: V = XW_v
    - Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V
    - MultiHead(Q,K,V) = Concat(head_1,...,head_h)W_o
    """
    def __init__(self, d_model, num_heads=8, dropout=0.1):
        # d_model: ç‰¹å¾ç»´åº¦ï¼Œå¿…é¡»èƒ½è¢«num_headsæ•´é™¤
        # num_heads: æ³¨æ„åŠ›å¤´æ•°ï¼Œå¢åŠ å¹¶è¡Œè®¡ç®—èƒ½åŠ›
        # dropout: é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–
        
    def forward(self, x):
        # è¾“å…¥: [B, N, d_model] - æ‰¹æ¬¡å¤§å°ï¼Œç‚¹æ•°ï¼Œç‰¹å¾ç»´åº¦
        # è¾“å‡º: [B, N, d_model] - ä¿æŒç»´åº¦ä¸å˜ï¼Œä½†ç‰¹å¾å·²è¢«æ³¨æ„åŠ›å¢å¼º
```

**å…³é”®å®ç°ç‰¹ç‚¹**:
- **ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›**: ä½¿ç”¨ `1/âˆšd_k` ç¼©æ”¾é˜²æ­¢æ¢¯åº¦æ¶ˆå¤±
- **å¤šå¤´å¹¶è¡Œ**: æ¯ä¸ªå¤´å…³æ³¨ä¸åŒçš„ç‰¹å¾å­ç©ºé—´
- **æ®‹å·®è¿æ¥**: `output = LayerNorm(input + attention_output)`
- **ä½ç½®æ„ŸçŸ¥**: ç»“åˆ3Dä½ç½®ç¼–ç ç†è§£ç©ºé—´å…³ç³»

### 3. PositionalEncoding3D è®¾è®¡åŸç†

```python
class PositionalEncoding3D(nn.Module):
    """ä¸“ä¸ºç‚¹äº‘è®¾è®¡çš„3Dä½ç½®ç¼–ç 
    
    è®¾è®¡æ€æƒ³:
    - ä¸åŒäºNLPä¸­çš„1Dä½ç½®ç¼–ç ï¼Œç‚¹äº‘éœ€è¦3Dç©ºé—´ä½ç½®ä¿¡æ¯
    - ä½¿ç”¨çº¿æ€§æŠ•å½±å°†(x,y,z)åæ ‡æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´
    - ä¿æŒå¹³ç§»ä¸å˜æ€§ï¼Œä½†ç¼–ç ç›¸å¯¹ä½ç½®å…³ç³»
    """
    def forward(self, points):
        # è¾“å…¥: [B, N, 3] - åŸå§‹3Dåæ ‡
        # è¾“å‡º: [B, N, d_model] - ä½ç½®ç¼–ç å‘é‡
        pos_encoding = self.pos_projection(points)
        return pos_encoding
```

**ä½ç½®ç¼–ç çš„ä½œç”¨**:
1. **ç©ºé—´æ„ŸçŸ¥**: è®©æ¨¡å‹ç†è§£ç‚¹åœ¨3Dç©ºé—´ä¸­çš„ä½ç½®å…³ç³»
2. **å‡ ä½•ç†è§£**: å¸®åŠ©è¯†åˆ«å±€éƒ¨å‡ ä½•ç»“æ„ï¼ˆå¹³é¢ã€è¾¹ç¼˜ã€è§’ç‚¹ï¼‰
3. **é…å‡†ä¼˜åŒ–**: å¯¹ç‚¹äº‘é…å‡†ä»»åŠ¡æä¾›å…³é”®çš„ç©ºé—´å¯¹åº”ä¿¡æ¯

### 4. èšåˆå‡½æ•°è¯¦è§£

```python
# 1. æœ€å¤§æ± åŒ–èšåˆ (PointNetå…¼å®¹)
def symfn_max(x):
    """[B, N, K] â†’ [B, K] ä¿ç•™æ¯ä¸ªç‰¹å¾ç»´åº¦çš„æœ€å¤§æ¿€æ´»å€¼"""
    return torch.max(x, dim=1)[0]

# 2. å¹³å‡æ± åŒ–èšåˆ (å…¨å±€ç‰¹å¾å¹³æ»‘)
def symfn_avg(x):
    """[B, N, K] â†’ [B, K] è®¡ç®—æ¯ä¸ªç‰¹å¾ç»´åº¦çš„å¹³å‡å€¼"""
    return torch.mean(x, dim=1)

# 3. æ³¨æ„åŠ›æ± åŒ–èšåˆ (AttentionNetä¸“ç”¨)
def symfn_attention_pool(x):
    """[B, N, K] â†’ [B, K] åŸºäºç‰¹å¾é‡è¦æ€§çš„è‡ªé€‚åº”åŠ æƒèšåˆ"""
    attention_weights = torch.softmax(torch.sum(x, dim=-1), dim=-1)
    return torch.sum(x * attention_weights.unsqueeze(-1), dim=1)
```

**èšåˆç­–ç•¥é€‰æ‹©**:
- **æœ€å¤§æ± åŒ–**: ä¿ç•™æ˜¾è‘—ç‰¹å¾ï¼Œé€‚åˆåˆ†ç±»ä»»åŠ¡
- **å¹³å‡æ± åŒ–**: å…¨å±€ç‰¹å¾å¹³æ»‘ï¼Œé€‚åˆé…å‡†ä»»åŠ¡
- **æ³¨æ„åŠ›æ± åŒ–**: è‡ªé€‚åº”é‡è¦æ€§æƒé‡ï¼Œæœ€é€‚åˆå¤æ‚åœºæ™¯

## ğŸ¯ APIå…¼å®¹æ€§è®¾è®¡

### å®Œå…¨å…¼å®¹çš„æ¥å£

| åŠŸèƒ½æ¨¡å— | PointNet | AttentionNet | å…¼å®¹æ€§çŠ¶æ€ |
|----------|----------|--------------|------------|
| **ç‰¹å¾æå–å™¨** | `PointNet_features` | `AttentionNet_features` | âœ… å®Œå…¨å…¼å®¹ |
| **åˆ†ç±»å™¨** | `PointNet_classifier` | `AttentionNet_classifier` | âœ… å®Œå…¨å…¼å®¹ |
| **è¾“å…¥æ ¼å¼** | `[B, N, 3]` | `[B, N, 3]` | âœ… ç›¸åŒ |
| **è¾“å‡ºæ ¼å¼** | `[B, K]` | `[B, K]` | âœ… ç›¸åŒ |
| **æŸå¤±å‡½æ•°** | `loss(out, target)` | `loss(out, target)` | âœ… ç›¸åŒ |
| **PointLKé›†æˆ** | æ”¯æŒ | æ”¯æŒ | âœ… é€æ˜æ›¿æ¢ |

### å…¼å®¹æ€§å®ç°ç»†èŠ‚

```python
# AttentionNetä¿æŒä¸PointNetç›¸åŒçš„å±æ€§
class AttentionNet_features:
    def __init__(self, dim_k=1024, sym_fn=symfn_max, scale=1, ...):
        # ä¿æŒç›¸åŒçš„åˆå§‹åŒ–å‚æ•°
        self.t_out_t2 = None    # PointNetå…¼å®¹å±æ€§
        self.t_out_h1 = None    # ä¸­é—´ç‰¹å¾å…¼å®¹å±æ€§
        
    def forward(self, points):
        # è¾“å…¥è¾“å‡ºæ ¼å¼å®Œå…¨ä¸€è‡´: [B, N, 3] â†’ [B, K]
        # å†…éƒ¨å¤„ç†ä¿æŒå…¼å®¹æ€§
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. ç‚¹äº‘é…å‡† (PointLK)

#### åŸºç¡€ä½¿ç”¨
```bash
# PointNeté…å‡† (åŸå§‹)
python experiments/train_pointlk.py \
    --model-type pointnet \
    --dim-k 1024 \
    --symfn max \
    --dataset-type c3vd \
    --dataset-path /path/to/dataset

# AttentionNeté…å‡† (æ–°)
python experiments/train_pointlk.py \
    --model-type attention \
    --dim-k 1024 \
    --num-attention-blocks 3 \
    --num-heads 8 \
    --symfn attention \
    --dataset-type c3vd \
    --dataset-path /path/to/dataset
```

#### é«˜çº§é…ç½®
```bash
# é«˜æ€§èƒ½attentioné…å‡†
python experiments/train_pointlk.py \
    --model-type attention \
    --dim-k 1024 \
    --num-attention-blocks 4 \
    --num-heads 12 \
    --symfn attention \
    --max-iter 20 \
    --delta 1e-3 \
    --learn-delta \
    --epochs 300 \
    --batch-size 16 \
    --optimizer Adam \
    --cosine-annealing
```

### 2. ç‚¹äº‘åˆ†ç±»

#### æ ‡å‡†åˆ†ç±»è®­ç»ƒ
```bash
# AttentionNetåˆ†ç±»å™¨
python experiments/train_classifier.py \
    --model-type attention \
    --num-attention-blocks 3 \
    --num-heads 8 \
    --dim-k 1024 \
    --symfn max \
    --dataset-type c3vd \
    --dataset-path /path/to/dataset \
    --categoryfile /path/to/categories.txt \
    --epochs 200 \
    --batch-size 32
```

#### é¢„è®­ç»ƒä¸è¿ç§»å­¦ä¹ 
```bash
# 1. é¦–å…ˆè®­ç»ƒåˆ†ç±»å™¨
python experiments/train_classifier.py \
    --model-type attention \
    --outfile classifier_model \
    [å…¶ä»–å‚æ•°...]

# 2. ä½¿ç”¨é¢„è®­ç»ƒæƒé‡è®­ç»ƒPointLK
python experiments/train_pointlk.py \
    --model-type attention \
    --transfer-from classifier_model_feat_best.pth \
    --outfile pointlk_model \
    [å…¶ä»–å‚æ•°...]
```

### 3. ç¼–ç¨‹æ¥å£ä½¿ç”¨

#### åŸºç¡€ç‰¹å¾æå–
```python
from ptlk.attention_v1 import AttentionNet_features, symfn_max

# åˆ›å»ºç‰¹å¾æå–å™¨
features = AttentionNet_features(
    dim_k=1024,                    # è¾“å‡ºç‰¹å¾ç»´åº¦
    sym_fn=symfn_max,              # èšåˆå‡½æ•°
    scale=1,                       # ç¼©æ”¾å› å­
    num_attention_blocks=3,        # Transformerå±‚æ•°
    num_heads=8                    # æ³¨æ„åŠ›å¤´æ•°
)

# ç‰¹å¾æå–
points = torch.randn(32, 1024, 3)  # [æ‰¹æ¬¡, ç‚¹æ•°, åæ ‡]
global_features = features(points)  # [32, 1024] å…¨å±€ç‰¹å¾å‘é‡
```

#### å®Œæ•´åˆ†ç±»å™¨
```python
from ptlk.attention_v1 import AttentionNet_features, AttentionNet_classifier

# åˆ›å»ºåˆ†ç±»å™¨
features = AttentionNet_features(dim_k=1024, num_attention_blocks=3)
classifier = AttentionNet_classifier(
    num_c=40,           # ç±»åˆ«æ•°
    attnfeat=features,  # ç‰¹å¾æå–å™¨
    dim_k=1024         # ç‰¹å¾ç»´åº¦
)

# åˆ†ç±»é¢„æµ‹
points = torch.randn(32, 1024, 3)
logits = classifier(points)        # [32, 40] åˆ†ç±»logits
loss = classifier.loss(logits, labels)  # è®¡ç®—æŸå¤±
```

#### PointLKé…å‡†é›†æˆ
```python
from ptlk.attention_v1 import AttentionNet_features
from ptlk.pointlk import PointLK

# åˆ›å»ºæ³¨æ„åŠ›ç‰¹å¾æå–å™¨
features = AttentionNet_features(
    dim_k=1024, 
    num_attention_blocks=3,
    num_heads=8
)

# åˆ›å»ºPointLKé…å‡†æ¨¡å‹
pointlk_model = PointLK(
    ptnet=features,     # ç‰¹å¾æå–å™¨
    delta=1e-2,         # é›…å¯æ¯”è¿‘ä¼¼æ­¥é•¿
    learn_delta=True    # æ˜¯å¦å­¦ä¹ æ­¥é•¿
)

# æ‰§è¡Œç‚¹äº‘é…å‡†
p0 = torch.randn(8, 1024, 3)  # ç›®æ ‡ç‚¹äº‘
p1 = torch.randn(8, 1024, 3)  # æºç‚¹äº‘

residual = PointLK.do_forward(
    pointlk_model, p0, p1, 
    maxiter=10,           # æœ€å¤§è¿­ä»£æ¬¡æ•°
    xtol=1e-7,           # æ”¶æ•›é˜ˆå€¼
    p0_zero_mean=True,   # ç›®æ ‡ç‚¹äº‘é›¶å‡å€¼
    p1_zero_mean=True    # æºç‚¹äº‘é›¶å‡å€¼
)

transformation = pointlk_model.g  # ä¼°è®¡çš„å˜æ¢çŸ©é˜µ [B, 4, 4]
```

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### AttentionNet_features å‚æ•°

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `dim_k` | int | 1024 | è¾“å‡ºç‰¹å¾å‘é‡ç»´åº¦ |
| `sym_fn` | function | symfn_max | èšåˆå‡½æ•° (max/avg/attention) |
| `scale` | int | 1 | æ¨¡å‹ç¼©æ”¾å› å­ (ç”¨äºè½»é‡åŒ–) |
| `num_attention_blocks` | int | 3 | Transformerå—æ•°é‡ |
| `num_heads` | int | 8 | å¤šå¤´æ³¨æ„åŠ›å¤´æ•° |

### è®­ç»ƒè„šæœ¬å‚æ•°

#### é€šç”¨å‚æ•°
```bash
# æ•°æ®é›†è®¾ç½®
--dataset-type {modelnet,shapenet2,c3vd}  # æ•°æ®é›†ç±»å‹
--dataset-path PATH                       # æ•°æ®é›†è·¯å¾„
--num-points 1024                        # æ¯ä¸ªç‚¹äº‘çš„ç‚¹æ•°

# æ¨¡å‹è®¾ç½®
--model-type {pointnet,attention}         # æ¨¡å‹ç±»å‹é€‰æ‹©
--dim-k 1024                             # ç‰¹å¾ç»´åº¦
--symfn {max,avg,attention}              # èšåˆå‡½æ•°

# AttentionNetä¸“ç”¨å‚æ•°
--num-attention-blocks 3                 # æ³¨æ„åŠ›å—æ•°é‡
--num-heads 8                           # æ³¨æ„åŠ›å¤´æ•°

# è®­ç»ƒè®¾ç½®  
--epochs 200                            # è®­ç»ƒè½®æ•°
--batch-size 32                         # æ‰¹æ¬¡å¤§å°
--optimizer {Adam,SGD}                  # ä¼˜åŒ–å™¨é€‰æ‹©
--cosine-annealing                      # ä½™å¼¦é€€ç«å­¦ä¹ ç‡
```

#### PointLKä¸“ç”¨å‚æ•°
```bash
--max-iter 10                           # LKæœ€å¤§è¿­ä»£æ¬¡æ•°
--delta 1e-2                           # é›…å¯æ¯”è¿‘ä¼¼æ­¥é•¿
--learn-delta                          # å­¦ä¹ æ­¥é•¿å‚æ•°
--mag 0.8                              # è®­ç»ƒæ—¶æ‰°åŠ¨å¹…åº¦
```

## ğŸ“Š æ€§èƒ½ç‰¹å¾å¯¹æ¯”

### è®¡ç®—å¤æ‚åº¦åˆ†æ

| æ¨¡å‹ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹å¾è¡¨è¾¾èƒ½åŠ› | é€‚ç”¨åœºæ™¯ |
|------|------------|------------|--------------|----------|
| **PointNet** | O(N) | O(N) | åŸºç¡€ | ç®€å•ç‚¹äº‘ä»»åŠ¡ |
| **AttentionNet** | O(NÂ²) | O(NÂ²) | å¼ºå¤§ | å¤æ‚å‡ ä½•ç†è§£ |

### å†…å­˜ä½¿ç”¨æŒ‡å—

| é…ç½®çº§åˆ« | GPUå†…å­˜éœ€æ±‚ | æ¨èå‚æ•° | é€‚ç”¨åœºæ™¯ |
|----------|-------------|----------|----------|
| **è½»é‡çº§** | < 8GB | `dim_k=512, blocks=2, heads=4` | å¼€å‘æµ‹è¯• |
| **æ ‡å‡†** | 8-16GB | `dim_k=1024, blocks=3, heads=8` | ä¸€èˆ¬åº”ç”¨ |
| **é«˜æ€§èƒ½** | > 16GB | `dim_k=1024, blocks=4, heads=12` | ç ”ç©¶å®éªŒ |

### è®­ç»ƒæ—¶é—´é¢„ä¼°

```bash
# åŸºäº1024ç‚¹ï¼Œ32æ‰¹æ¬¡å¤§å°çš„å…¸å‹è®­ç»ƒæ—¶é—´ (å•GPU)
PointNet:     ~2-3 ç§’/è½®  (100-200è½®æ”¶æ•›)
AttentionNet: ~8-12ç§’/è½®  (150-300è½®æ”¶æ•›)

# å¤šGPUå¹¶è¡Œå¯æ˜¾è‘—åŠ é€Ÿè®­ç»ƒ
```

## ğŸ”§ é«˜çº§é…ç½®ä¸ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–ç­–ç•¥

```python
# æ¢¯åº¦æ£€æŸ¥ç‚¹ (å‡å°‘å†…å­˜ä½¿ç”¨)
from torch.utils.checkpoint import checkpoint

class OptimizedAttentionBlock(nn.Module):
    def forward(self, x):
        # ä½¿ç”¨æ£€æŸ¥ç‚¹å‡å°‘ä¸­é—´æ¿€æ´»çš„å†…å­˜å ç”¨
        x = checkpoint(self.self_attention, x)
        x = checkpoint(self.feed_forward, x)
        return x

# æ··åˆç²¾åº¦è®­ç»ƒ (å‡å°‘å†…å­˜ï¼ŒåŠ é€Ÿè®­ç»ƒ)
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    output = model(inputs)
    loss = criterion(output, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### 2. åŠ¨æ€è°ƒæ•´ç­–ç•¥

```python
# è‡ªé€‚åº”æ³¨æ„åŠ›å¤´æ•°
def adaptive_heads(epoch, base_heads=8):
    """è®­ç»ƒåˆæœŸä½¿ç”¨è¾ƒå°‘å¤´æ•°ï¼ŒåæœŸå¢åŠ å¤æ‚åº¦"""
    if epoch < 50:
        return base_heads // 2
    elif epoch < 100:
        return base_heads
    else:
        return base_heads + 2

# æ¸è¿›å¼è®­ç»ƒç­–ç•¥
def progressive_training(model, epoch):
    """é€æ­¥å¢åŠ æ¨¡å‹å¤æ‚åº¦"""
    if epoch < 30:
        # å‰30è½®åªè®­ç»ƒåŸºç¡€å±‚
        for i, block in enumerate(model.attention_blocks):
            if i > 1:
                for param in block.parameters():
                    param.requires_grad = False
    else:
        # 30è½®åå¼€æ”¾æ‰€æœ‰å±‚
        for param in model.parameters():
            param.requires_grad = True
```

### 3. æ•°æ®å¢å¼ºç­–ç•¥

```python
# é’ˆå¯¹ç‚¹äº‘çš„æ•°æ®å¢å¼º
class PointCloudAugmentation:
    def __init__(self):
        self.transforms = [
            self.random_rotation,
            self.random_scaling,
            self.random_jitter,
            self.random_dropout
        ]
    
    def random_rotation(self, points):
        """éšæœºæ—‹è½¬å¢å¼ºå‡ ä½•ä¸å˜æ€§"""
        angle = torch.rand(1) * 2 * math.pi
        rotation_matrix = self.get_rotation_matrix(angle)
        return torch.matmul(points, rotation_matrix)
    
    def random_scaling(self, points):
        """éšæœºç¼©æ”¾å¢å¼ºå°ºåº¦ä¸å˜æ€§"""
        scale = 0.8 + torch.rand(1) * 0.4  # [0.8, 1.2]
        return points * scale
    
    def random_jitter(self, points):
        """æ·»åŠ å™ªå£°æé«˜é²æ£’æ€§"""
        noise = torch.randn_like(points) * 0.01
        return points + noise
    
    def random_dropout(self, points):
        """éšæœºä¸¢å¼ƒç‚¹æ¨¡æ‹Ÿé®æŒ¡"""
        keep_ratio = 0.8 + torch.rand(1) * 0.15  # [0.8, 0.95]
        num_keep = int(points.shape[1] * keep_ratio)
        indices = torch.randperm(points.shape[1])[:num_keep]
        return points[:, indices, :]
```

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### åŠŸèƒ½æµ‹è¯•
```bash
# å®Œæ•´åŠŸèƒ½æµ‹è¯• (éœ€è¦PyTorchç¯å¢ƒ)
python test_attention.py

# å¿«é€Ÿè¯­æ³•æ£€æŸ¥ (æ— éœ€æ·±åº¦å­¦ä¹ ä¾èµ–)
python -m py_compile ptlk/attention_v1.py
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•
```python
import time
import torch
from ptlk.attention_v1 import AttentionNet_features
from ptlk.pointnet import PointNet_features

def benchmark_models():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    points = torch.randn(32, 1024, 3).to(device)
    
    # PointNetåŸºå‡†
    pointnet = PointNet_features().to(device)
    start_time = time.time()
    for _ in range(100):
        _ = pointnet(points)
    pointnet_time = time.time() - start_time
    
    # AttentionNetåŸºå‡†
    attention = AttentionNet_features().to(device)
    start_time = time.time()
    for _ in range(100):
        _ = attention(points)
    attention_time = time.time() - start_time
    
    print(f"PointNetå¹³å‡æ—¶é—´: {pointnet_time/100:.4f}ç§’")
    print(f"AttentionNetå¹³å‡æ—¶é—´: {attention_time/100:.4f}ç§’")
    print(f"é€Ÿåº¦æ¯”ç‡: {attention_time/pointnet_time:.2f}x")

benchmark_models()
```

## ğŸ“š ç†è®ºèƒŒæ™¯ä¸å‚è€ƒæ–‡çŒ®

### æ ¸å¿ƒç†è®ºåŸºç¡€

1. **æ³¨æ„åŠ›æœºåˆ¶**: Vaswani et al. "Attention Is All You Need" (2017)
   - è‡ªæ³¨æ„åŠ›è®¡ç®—ç‚¹ä¸ç‚¹ä¹‹é—´çš„ç›¸å…³æ€§
   - å¤šå¤´æœºåˆ¶æ•è·ä¸åŒç±»å‹çš„ç‰¹å¾å…³ç³»

2. **PointNetæ¶æ„**: Qi et al. "PointNet: Deep Learning on Point Sets" (2017)
   - ç½®æ¢ä¸å˜æ€§çš„é‡è¦æ€§
   - ç‚¹äº‘çš„èšåˆç­–ç•¥è®¾è®¡

3. **PointNetLKç®—æ³•**: Aoki et al. "PointNetLK: Robust & Efficient Point Cloud Registration" (2019)
   - Lucas-Kanadeè¿­ä»£ä¼˜åŒ–
   - ç‰¹å¾ç©ºé—´ä¸­çš„é…å‡†ç®—æ³•

### æ”¹è¿›ä¸åˆ›æ–°ç‚¹

1. **3Dä½ç½®ç¼–ç è®¾è®¡**: ä¸“é—¨é’ˆå¯¹ä¸‰ç»´ç‚¹äº‘çš„ä½ç½®è¡¨ç¤º
2. **å¤šå°ºåº¦æ³¨æ„åŠ›**: ä»å±€éƒ¨ç»†èŠ‚åˆ°å…¨å±€ç»“æ„çš„å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹ 
3. **é…å‡†ä»»åŠ¡ä¼˜åŒ–**: é’ˆå¯¹ç‚¹äº‘é…å‡†ä»»åŠ¡çš„ç‰¹å¾ç©ºé—´è®¾è®¡
4. **å†…å­˜æ•ˆç‡ä¼˜åŒ–**: å¤§è§„æ¨¡ç‚¹äº‘å¤„ç†çš„å®ç”¨æ€§è€ƒè™‘

## ğŸ¤ å¼€å‘æŒ‡å—

### æ‰©å±•æ–°åŠŸèƒ½

```python
# 1. æ·»åŠ æ–°çš„èšåˆå‡½æ•°
def symfn_weighted_avg(x, weights=None):
    """åŠ æƒå¹³å‡èšåˆ"""
    if weights is None:
        weights = torch.ones(x.shape[1]) / x.shape[1]
    weights = weights.unsqueeze(0).unsqueeze(-1)  # [1, N, 1]
    return torch.sum(x * weights, dim=1)

# 2. è‡ªå®šä¹‰æ³¨æ„åŠ›å—
class CrossAttentionBlock(nn.Module):
    """äº¤å‰æ³¨æ„åŠ›å—ï¼Œç”¨äºåŒç‚¹äº‘ç‰¹å¾èåˆ"""
    def __init__(self, d_model, num_heads=8):
        super().__init__()
        self.cross_attention = MultiHeadCrossAttention(d_model, num_heads)
        self.feed_forward = FeedForwardNetwork(d_model, d_model*4)
    
    def forward(self, query_points, key_points):
        attended = self.cross_attention(query_points, key_points)
        output = self.feed_forward(attended)
        return output

# 3. å±‚æ¬¡åŒ–æ³¨æ„åŠ›
class HierarchicalAttentionNet(nn.Module):
    """å±‚æ¬¡åŒ–æ³¨æ„åŠ›ç½‘ç»œï¼Œå¤„ç†å¤šåˆ†è¾¨ç‡ç‚¹äº‘"""
    def __init__(self, scales=[1024, 512, 256]):
        super().__init__()
        self.scales = scales
        self.attention_nets = nn.ModuleList([
            AttentionNet_features(dim_k=1024//i) 
            for i in [1, 2, 4]
        ])
        
    def forward(self, points):
        features = []
        for i, net in enumerate(self.attention_nets):
            # å¤šåˆ†è¾¨ç‡é‡‡æ ·
            sampled = self.sample_points(points, self.scales[i])
            feat = net(sampled)
            features.append(feat)
        
        # ç‰¹å¾èåˆ
        return torch.cat(features, dim=1)
```

### è´¡çŒ®ä»£ç 

1. **ä»£ç è§„èŒƒ**: éµå¾ªPEP 8æ ‡å‡†ï¼Œæ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
2. **æµ‹è¯•ç”¨ä¾‹**: ä¸ºæ–°åŠŸèƒ½ç¼–å†™ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹
3. **æ€§èƒ½åŸºå‡†**: æä¾›æ€§èƒ½å¯¹æ¯”æ•°æ®
4. **æ–‡æ¡£æ›´æ–°**: æ›´æ–°READMEå’ŒAPIæ–‡æ¡£

## ğŸ¯ åº”ç”¨åœºæ™¯

### 1. 3Dç›®æ ‡æ£€æµ‹
```python
# ç»“åˆAttentionNetè¿›è¡Œ3Dç›®æ ‡æ£€æµ‹
class PointCloudDetector(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.backbone = AttentionNet_features(dim_k=512)
        self.bbox_head = nn.Linear(512, num_classes * 7)  # cls + bbox
        
    def forward(self, points):
        features = self.backbone(points)
        predictions = self.bbox_head(features)
        return predictions.view(-1, num_classes, 7)
```

### 2. ç‚¹äº‘åˆ†å‰²
```python
# ç‚¹çº§åˆ†å‰²ä»»åŠ¡
class PointSegmentation(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.attention_net = AttentionNet_features(dim_k=256)
        self.seg_head = nn.Conv1d(256, num_classes, 1)
        
    def forward(self, points):
        # è·å–æ¯ç‚¹ç‰¹å¾è€Œéå…¨å±€ç‰¹å¾
        point_features = self.attention_net.get_point_features(points)
        segmentation = self.seg_head(point_features.transpose(1, 2))
        return segmentation.transpose(1, 2)
```

### 3. åœºæ™¯ç†è§£
```python
# å®¤å†…åœºæ™¯ç†è§£
class SceneUnderstanding(nn.Module):
    def __init__(self):
        super().__init__()
        self.attention_net = AttentionNet_features(dim_k=1024)
        self.scene_classifier = nn.Linear(1024, 10)  # æˆ¿é—´ç±»å‹
        self.object_detector = nn.Linear(1024, 20 * 6)  # ç‰©ä½“+ä½ç½®
        
    def forward(self, points):
        global_features = self.attention_net(points)
        scene_type = self.scene_classifier(global_features)
        object_detections = self.object_detector(global_features)
        return scene_type, object_detections
```

## ğŸš¨ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. å†…å­˜ä¸è¶³ (OOM)
```python
# è§£å†³æ–¹æ¡ˆ1: å‡å°‘æ‰¹æ¬¡å¤§å°å’Œç‚¹æ•°
--batch-size 16 --num-points 512

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
torch.utils.checkpoint.checkpoint(attention_block, x)

# è§£å†³æ–¹æ¡ˆ3: åˆ†æ®µå¤„ç†å¤§ç‚¹äº‘
def process_large_pointcloud(points, chunk_size=1024):
    results = []
    for i in range(0, points.shape[1], chunk_size):
        chunk = points[:, i:i+chunk_size, :]
        result = model(chunk)
        results.append(result)
    return torch.cat(results, dim=1)
```

### 2. è®­ç»ƒä¸æ”¶æ•›
```python
# è§£å†³æ–¹æ¡ˆ1: è°ƒæ•´å­¦ä¹ ç‡
optimizer = torch.optim.Adam(params, lr=1e-4)  # é™ä½å­¦ä¹ ç‡
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)

# è§£å†³æ–¹æ¡ˆ2: æ¢¯åº¦è£å‰ª
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# è§£å†³æ–¹æ¡ˆ3: é¢„çƒ­è®­ç»ƒ
def warmup_learning_rate(epoch, base_lr, warmup_epochs=10):
    if epoch < warmup_epochs:
        return base_lr * (epoch + 1) / warmup_epochs
    return base_lr
```

### 3. æ¨ç†é€Ÿåº¦æ…¢
```python
# è§£å†³æ–¹æ¡ˆ1: æ¨¡å‹é‡åŒ–
import torch.quantization as quantization
quantized_model = quantization.quantize_dynamic(model, dtype=torch.qint8)

# è§£å†³æ–¹æ¡ˆ2: æ¨¡å‹å‰ªæ
import torch.nn.utils.prune as prune
prune.global_unstructured(model.parameters(), pruning_method=prune.L1Unstructured, amount=0.2)

# è§£å†³æ–¹æ¡ˆ3: ä½¿ç”¨TensorRTä¼˜åŒ–
import torch2trt
model_trt = torch2trt.torch2trt(model, [example_input])
```

---

## ğŸ‰ æ€»ç»“

AttentionNetå·²æˆåŠŸé›†æˆåˆ°PointNetLKé¡¹ç›®ä¸­ï¼Œæä¾›äº†å¼ºå¤§çš„ç‚¹äº‘ç‰¹å¾å­¦ä¹ èƒ½åŠ›ã€‚é€šè¿‡å®Œæ•´çš„APIå…¼å®¹æ€§è®¾è®¡ï¼Œç”¨æˆ·å¯ä»¥æ— ç¼æ›¿æ¢åŸæœ‰çš„PointNetæ¨¡å—ï¼Œäº«å—Transformeræ³¨æ„åŠ›æœºåˆ¶å¸¦æ¥çš„æ€§èƒ½æå‡ã€‚

æ— è®ºæ˜¯ç‚¹äº‘é…å‡†ã€åˆ†ç±»è¿˜æ˜¯å…¶ä»–ä¸‰ç»´ç†è§£ä»»åŠ¡ï¼ŒAttentionNetéƒ½èƒ½æä¾›æ›´ç²¾ç¡®çš„ç‰¹å¾è¡¨ç¤ºå’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ç»“åˆè¯¦ç»†çš„é…ç½®é€‰é¡¹å’Œä¼˜åŒ–ç­–ç•¥ï¼Œæœ¬å®ç°æ—¢é€‚åˆç ”ç©¶æ¢ç´¢ï¼Œä¹Ÿå…·å¤‡å·¥ä¸šåº”ç”¨çš„å®ç”¨æ€§ã€‚

**ğŸš€ ç°åœ¨å°±å¼€å§‹ä½¿ç”¨AttentionNetï¼Œä½“éªŒä¸‹ä¸€ä»£ç‚¹äº‘æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼** 