# PointNetLK with 3DMamba Embedding - å®Œæ•´å®ç°æ–‡æ¡£

## ğŸš€ æ¦‚è¿°

æœ¬é¡¹ç›®æˆåŠŸå¼€å‘å¹¶é›†æˆäº†åŸºäºMambaçŠ¶æ€ç©ºé—´æ¨¡å‹(SSM)çš„ç‚¹äº‘ç‰¹å¾æå–å™¨ï¼Œä¸“ä¸ºç‚¹äº‘é…å‡†å’Œåˆ†ç±»ä»»åŠ¡è®¾è®¡ã€‚Mamba3Dæ¨¡å—å®Œå…¨æ›¿æ¢åŸå§‹PointNetï¼Œæä¾›æ›´é«˜æ•ˆçš„åºåˆ—å»ºæ¨¡èƒ½åŠ›å’Œçº¿æ€§è®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶ä¿æŒå®Œå…¨çš„APIå…¼å®¹æ€§ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ§  ä¸»è¦æŠ€æœ¯ä¼˜åŠ¿
- **ğŸ”¥ çŠ¶æ€ç©ºé—´æ¨¡å‹**: é«˜æ•ˆå¤„ç†é•¿åºåˆ—æ•°æ®ï¼Œæ•è·é•¿è·ç¦»ä¾èµ–å…³ç³»
- **ğŸŒŸ 3Dä½ç½®ç¼–ç **: æ˜¾å¼ä¿ç•™å’Œåˆ©ç”¨ç‚¹äº‘çš„ä¸‰ç»´ç©ºé—´ç»“æ„ä¿¡æ¯
- **âš¡ çº¿æ€§å¤æ‚åº¦**: ç›¸æ¯”æ³¨æ„åŠ›æœºåˆ¶çš„äºŒæ¬¡å¤æ‚åº¦ï¼Œæä¾›æ›´é«˜æ•ˆçš„è®¡ç®—
- **ğŸ¯ é€‰æ‹©æ€§æ‰«æ**: é’ˆå¯¹3Dç‚¹äº‘è®¾è®¡çš„æ‰«ææœºåˆ¶ï¼Œæœ‰æ•ˆå¤„ç†ç©ºé—´ä¿¡æ¯
- **ğŸ”„ ç½®æ¢ä¸å˜æ€§**: å¤©ç„¶é€‚åº”ç‚¹äº‘æ•°æ®çš„æ— åºç‰¹æ€§
- **ğŸ›ï¸ çµæ´»é…ç½®**: æ”¯æŒå¤šç§æ¶æ„é…ç½®å’Œèšåˆç­–ç•¥
- **ğŸ”— å®Œå…¨å…¼å®¹**: ä¸åŸå§‹PointNetä¿æŒ100%çš„APIå…¼å®¹æ€§

## ğŸ“‹ æ–‡ä»¶ç»“æ„

```
PointNetLK_c3vd/
â”œâ”€â”€ ptlk/
â”‚   â”œâ”€â”€ mamba3d_v1.py          # ğŸ§  3DMambaæ¨¡å—æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ attention_v1.py        # æ³¨æ„åŠ›æ¨¡å—å®ç°ï¼ˆå¯¹æ¯”ç”¨ï¼‰
â”‚   â”œâ”€â”€ pointlk.py             # ğŸ”— PointLKç®—æ³• (æ”¯æŒMamba3D)
â”‚   â””â”€â”€ pointnet.py            # ğŸ“¦ åŸå§‹PointNetå®ç°
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train_pointlk.py       # ğŸš‚ ç‚¹äº‘é…å‡†è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ train_classifier.py    # ğŸ·ï¸ ç‚¹äº‘åˆ†ç±»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ MAMBA3D_README.md          # ğŸ“– æœ¬æ–‡æ¡£
â”œâ”€â”€ test_mamba3d.py            # ğŸ§ª åŠŸèƒ½æµ‹è¯•è„šæœ¬
â””â”€â”€ test_attention.py          # æ³¨æ„åŠ›æ¨¡å—æµ‹è¯•è„šæœ¬
```

## ğŸ—ï¸ è¯¦ç»†æ¶æ„è®¾è®¡

### 1. æ ¸å¿ƒæ¨¡å—å±‚æ¬¡ç»“æ„

```
Mamba3D_features (ä¸»ç‰¹å¾æå–å™¨)
â”œâ”€â”€ input_projection: Linear(3 â†’ d_model)         # è¾“å…¥åµŒå…¥å±‚
â”œâ”€â”€ pos_encoding: PositionalEncoding3D            # ä½ç½®ç¼–ç 
â”œâ”€â”€ mamba_blocks: ModuleList[Mamba3DBlock]        # å¤šå±‚Mambaå—
â”‚   â””â”€â”€ Mamba3DBlock (é‡å¤Næ¬¡)
â”‚       â”œâ”€â”€ s6_layer: S6Layer                     # æ ¸å¿ƒçŠ¶æ€ç©ºé—´å±‚
â”‚       â””â”€â”€ feed_forward: FeedForwardNetwork      # å‰é¦ˆç½‘ç»œ
â”œâ”€â”€ feature_transform: MLPNet                     # ç‰¹å¾å˜æ¢å±‚
â””â”€â”€ sy: Aggregation Function                      # å…¨å±€èšåˆå‡½æ•°
```

### 2. S6Layer å®ç°ç»†èŠ‚

```python
class S6Layer(nn.Module):
    """ç®€åŒ–ç‰ˆæœ¬çš„Mamba S6å±‚ï¼Œé€‚ç”¨äº3Dç‚¹äº‘
    
    æ•°å­¦åŸç†:
    - çŠ¶æ€ç©ºé—´æ¨¡å‹æ–¹ç¨‹: x'(t) = Ax(t) + Bu(t), y(t) = Cx(t)
    - å…¶ä¸­Aæ˜¯çŠ¶æ€çŸ©é˜µï¼ŒBæ˜¯è¾“å…¥çŸ©é˜µï¼ŒCæ˜¯è¾“å‡ºçŸ©é˜µ
    - ç¦»æ•£åŒ–å: x_t = (A_dt)x_{t-1} + (B_dt)u_t, y_t = Cx_t
    - A_dt = exp(A*dt), B_dt = B*dt
    """
    def __init__(self, d_model, d_state=16, expand=2, dt_min=0.001, dt_max=0.1):
        # d_model: ç‰¹å¾ç»´åº¦
        # d_state: éšè—çŠ¶æ€ç»´åº¦
        # expand: æ‰©å±•æ¯”ä¾‹ï¼Œæ§åˆ¶å†…éƒ¨ç»´åº¦
        # dt_min/dt_max: æ—¶é—´æ­¥é•¿å‚æ•°èŒƒå›´
        
    def forward(self, x):
        # è¾“å…¥: [B, N, d_model] - æ‰¹æ¬¡å¤§å°ï¼Œç‚¹æ•°ï¼Œç‰¹å¾ç»´åº¦
        # è¾“å‡º: [B, N, d_model] - ä¿æŒç»´åº¦ä¸å˜ï¼Œä½†ç‰¹å¾å·²è¢«SSMå¢å¼º
```

**å…³é”®å®ç°ç‰¹ç‚¹**:
- **çŠ¶æ€ç©ºé—´æ¨¡å‹**: é€šè¿‡SSMæ•è·åºåˆ—ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»
- **ç¦»æ•£åŒ–**: ä½¿ç”¨æŒ‡æ•°å‡½æ•°è¿›è¡Œç¦»æ•£åŒ–ï¼Œä¿è¯ç¨³å®šæ€§
- **å‚æ•°åŒ–æ—¶é—´æ­¥é•¿**: æ¯ä¸ªç‰¹å¾é€šé“ä½¿ç”¨ç‹¬ç«‹çš„æ—¶é—´æ­¥é•¿å‚æ•°
- **æ®‹å·®è¿æ¥**: `output = input + ssm_output`
- **å±‚å½’ä¸€åŒ–**: æé«˜è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦

### 3. PositionalEncoding3D è®¾è®¡åŸç†

```python
class PositionalEncoding3D(nn.Module):
    """ä¸“ä¸ºç‚¹äº‘è®¾è®¡çš„3Dä½ç½®ç¼–ç 
    
    è®¾è®¡æ€æƒ³:
    - ä¸åŒäºNLPä¸­çš„1Dä½ç½®ç¼–ç ï¼Œç‚¹äº‘éœ€è¦3Dç©ºé—´ä½ç½®ä¿¡æ¯
    - ä½¿ç”¨çº¿æ€§æŠ•å½±å°†(x,y,z)åæ ‡æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´
    - ä¿æŒå¹³ç§»ä¸å˜æ€§ï¼Œä½†ç¼–ç ç›¸å¯¹ä½ç½®å…³ç³»
    """
    def forward(self, points):
        # è¾“å…¥: [B, N, 3] - åŸå§‹3Dåæ ‡
        # è¾“å‡º: [B, N, d_model] - ä½ç½®ç¼–ç å‘é‡
        pos_encoding = self.pos_projection(points)
        return pos_encoding
```

**ä½ç½®ç¼–ç çš„ä½œç”¨**:
1. **ç©ºé—´æ„ŸçŸ¥**: è®©æ¨¡å‹ç†è§£ç‚¹åœ¨3Dç©ºé—´ä¸­çš„ä½ç½®å…³ç³»
2. **å‡ ä½•ç†è§£**: å¸®åŠ©è¯†åˆ«å±€éƒ¨å‡ ä½•ç»“æ„ï¼ˆå¹³é¢ã€è¾¹ç¼˜ã€è§’ç‚¹ï¼‰
3. **é…å‡†ä¼˜åŒ–**: å¯¹ç‚¹äº‘é…å‡†ä»»åŠ¡æä¾›å…³é”®çš„ç©ºé—´å¯¹åº”ä¿¡æ¯

### 4. èšåˆå‡½æ•°è¯¦è§£

```python
# 1. æœ€å¤§æ± åŒ–èšåˆ (PointNetå…¼å®¹)
def symfn_max(x):
    """[B, N, K] â†’ [B, K] ä¿ç•™æ¯ä¸ªç‰¹å¾ç»´åº¦çš„æœ€å¤§æ¿€æ´»å€¼"""
    return torch.max(x, dim=1)[0]

# 2. å¹³å‡æ± åŒ–èšåˆ (å…¨å±€ç‰¹å¾å¹³æ»‘)
def symfn_avg(x):
    """[B, N, K] â†’ [B, K] è®¡ç®—æ¯ä¸ªç‰¹å¾ç»´åº¦çš„å¹³å‡å€¼"""
    return torch.mean(x, dim=1)

# 3. é€‰æ‹©æ€§èšåˆ (Mamba3Dä¸“ç”¨)
def symfn_selective(x):
    """[B, N, K] â†’ [B, K] åŸºäºç‰¹å¾é‡è¦æ€§çš„è‡ªé€‚åº”åŠ æƒèšåˆ"""
    weights = torch.softmax(torch.sum(x, dim=-1), dim=-1)
    return torch.sum(x * weights.unsqueeze(-1), dim=1)
```

**èšåˆç­–ç•¥é€‰æ‹©**:
- **æœ€å¤§æ± åŒ–**: ä¿ç•™æ˜¾è‘—ç‰¹å¾ï¼Œé€‚åˆåˆ†ç±»ä»»åŠ¡
- **å¹³å‡æ± åŒ–**: å…¨å±€ç‰¹å¾å¹³æ»‘ï¼Œé€‚åˆé…å‡†ä»»åŠ¡
- **é€‰æ‹©æ€§èšåˆ**: è‡ªé€‚åº”é‡è¦æ€§æƒé‡ï¼Œæœ€é€‚åˆå¤æ‚åœºæ™¯

## ğŸ¯ APIå…¼å®¹æ€§è®¾è®¡

### å®Œå…¨å…¼å®¹çš„æ¥å£

| åŠŸèƒ½æ¨¡å— | PointNet | Mamba3D | å…¼å®¹æ€§çŠ¶æ€ |
|----------|----------|-----------|------------|
| **ç‰¹å¾æå–å™¨** | `PointNet_features` | `Mamba3D_features` | âœ… å®Œå…¨å…¼å®¹ |
| **åˆ†ç±»å™¨** | `PointNet_classifier` | `Mamba3D_classifier` | âœ… å®Œå…¨å…¼å®¹ |
| **è¾“å…¥æ ¼å¼** | `[B, N, 3]` | `[B, N, 3]` | âœ… ç›¸åŒ |
| **è¾“å‡ºæ ¼å¼** | `[B, K]` | `[B, K]` | âœ… ç›¸åŒ |
| **æŸå¤±å‡½æ•°** | `loss(out, target)` | `loss(out, target)` | âœ… ç›¸åŒ |
| **PointLKé›†æˆ** | æ”¯æŒ | æ”¯æŒ | âœ… é€æ˜æ›¿æ¢ |

### å…¼å®¹æ€§å®ç°ç»†èŠ‚

```python
# Mamba3Dä¿æŒä¸PointNetç›¸åŒçš„å±æ€§
class Mamba3D_features:
    def __init__(self, dim_k=1024, sym_fn=symfn_max, scale=1, ...):
        # ä¿æŒç›¸åŒçš„åˆå§‹åŒ–å‚æ•°
        self.t_out_t2 = None    # PointNetå…¼å®¹å±æ€§
        self.t_out_h1 = None    # ä¸­é—´ç‰¹å¾å…¼å®¹å±æ€§
        
    def forward(self, points):
        # è¾“å…¥è¾“å‡ºæ ¼å¼å®Œå…¨ä¸€è‡´: [B, N, 3] â†’ [B, K]
        # å†…éƒ¨å¤„ç†ä¿æŒå…¼å®¹æ€§
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. ç‚¹äº‘é…å‡† (PointLK)

#### åŸºç¡€ä½¿ç”¨
```bash
# PointNeté…å‡† (åŸå§‹)
python experiments/train_pointlk.py \
    --model-type pointnet \
    --dim-k 1024 \
    --symfn max \
    --dataset-type c3vd \
    --dataset-path /path/to/dataset

# Mamba3Dé…å‡† (æ–°)
python experiments/train_pointlk.py \
    --model-type mamba3d \
    --dim-k 1024 \
    --num-mamba-blocks 3 \
    --d-state 16 \
    --symfn selective \
    --dataset-type c3vd \
    --dataset-path /path/to/dataset
```

#### é«˜çº§é…ç½®
```bash
# é«˜æ€§èƒ½Mamba3Dé…å‡†
python experiments/train_pointlk.py \
    --model-type mamba3d \
    --dim-k 1024 \
    --num-mamba-blocks 4 \
    --d-state 32 \
    --expand 3 \
    --symfn selective \
    --max-iter 20 \
    --delta 1e-3 \
    --learn-delta \
    --epochs 300 \
    --batch-size 16 \
    --optimizer Adam \
    --cosine-annealing
```

### 2. ç‚¹äº‘åˆ†ç±»

#### æ ‡å‡†åˆ†ç±»è®­ç»ƒ
```bash
# Mamba3Dåˆ†ç±»å™¨
python experiments/train_classifier.py \
    --model-type mamba3d \
    --num-mamba-blocks 3 \
    --d-state 16 \
    --dim-k 1024 \
    --symfn max \
    --dataset-type c3vd \
    --dataset-path /path/to/dataset \
    --categoryfile /path/to/categories.txt \
    --epochs 200 \
    --batch-size 32
```

#### é¢„è®­ç»ƒä¸è¿ç§»å­¦ä¹ 
```bash
# 1. é¦–å…ˆè®­ç»ƒåˆ†ç±»å™¨
python experiments/train_classifier.py \
    --model-type mamba3d \
    --outfile classifier_model \
    [å…¶ä»–å‚æ•°...]

# 2. ä½¿ç”¨é¢„è®­ç»ƒæƒé‡è®­ç»ƒPointLK
python experiments/train_pointlk.py \
    --model-type mamba3d \
    --transfer-from classifier_model_feat_best.pth \
    --outfile pointlk_model \
    [å…¶ä»–å‚æ•°...]
```

### 3. ç¼–ç¨‹æ¥å£ä½¿ç”¨

#### åŸºç¡€ç‰¹å¾æå–
```python
from ptlk.mamba3d_v1 import Mamba3D_features, symfn_max

# åˆ›å»ºç‰¹å¾æå–å™¨
features = Mamba3D_features(
    dim_k=1024,                   # è¾“å‡ºç‰¹å¾ç»´åº¦
    sym_fn=symfn_max,             # èšåˆå‡½æ•°
    scale=1,                      # ç¼©æ”¾å› å­
    num_mamba_blocks=3,           # Mambaå—æ•°é‡
    d_state=16                    # çŠ¶æ€ç»´åº¦
)

# ç‰¹å¾æå–
points = torch.randn(32, 1024, 3)  # [æ‰¹æ¬¡, ç‚¹æ•°, åæ ‡]
global_features = features(points)  # [32, 1024] å…¨å±€ç‰¹å¾å‘é‡
```

#### å®Œæ•´åˆ†ç±»å™¨
```python
from ptlk.mamba3d_v1 import Mamba3D_features, Mamba3D_classifier

# åˆ›å»ºåˆ†ç±»å™¨
features = Mamba3D_features(dim_k=1024, num_mamba_blocks=3)
classifier = Mamba3D_classifier(
    num_c=40,           # ç±»åˆ«æ•°
    mambafeat=features, # ç‰¹å¾æå–å™¨
    dim_k=1024          # ç‰¹å¾ç»´åº¦
)

# åˆ†ç±»é¢„æµ‹
points = torch.randn(32, 1024, 3)
logits = classifier(points)        # [32, 40] åˆ†ç±»logits
loss = classifier.loss(logits, labels)  # è®¡ç®—æŸå¤±
```

#### PointLKé…å‡†é›†æˆ
```python
from ptlk.mamba3d_v1 import Mamba3D_features
from ptlk.pointlk import PointLK

# åˆ›å»ºMamba3Dç‰¹å¾æå–å™¨
features = Mamba3D_features(
    dim_k=1024, 
    num_mamba_blocks=3,
    d_state=16
)

# åˆ›å»ºPointLKé…å‡†æ¨¡å‹
pointlk_model = PointLK(
    ptnet=features,     # ç‰¹å¾æå–å™¨
    delta=1e-2,         # é›…å¯æ¯”è¿‘ä¼¼æ­¥é•¿
    learn_delta=True    # æ˜¯å¦å­¦ä¹ æ­¥é•¿
)

# æ‰§è¡Œç‚¹äº‘é…å‡†
p0 = torch.randn(8, 1024, 3)  # ç›®æ ‡ç‚¹äº‘
p1 = torch.randn(8, 1024, 3)  # æºç‚¹äº‘

residual = PointLK.do_forward(
    pointlk_model, p0, p1, 
    maxiter=10,           # æœ€å¤§è¿­ä»£æ¬¡æ•°
    xtol=1e-7,           # æ”¶æ•›é˜ˆå€¼
    p0_zero_mean=True,   # ç›®æ ‡ç‚¹äº‘é›¶å‡å€¼
    p1_zero_mean=True    # æºç‚¹äº‘é›¶å‡å€¼
)

transformation = pointlk_model.g  # ä¼°è®¡çš„å˜æ¢çŸ©é˜µ [B, 4, 4]
```

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### Mamba3D_features å‚æ•°

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `dim_k` | int | 1024 | è¾“å‡ºç‰¹å¾å‘é‡ç»´åº¦ |
| `sym_fn` | function | symfn_max | èšåˆå‡½æ•° (max/avg/selective) |
| `scale` | int | 1 | æ¨¡å‹ç¼©æ”¾å› å­ (ç”¨äºè½»é‡åŒ–) |
| `num_mamba_blocks` | int | 3 | Mambaå—æ•°é‡ |
| `d_state` | int | 16 | çŠ¶æ€ç©ºé—´ç»´åº¦ |
| `expand` | int | 2 | ç‰¹å¾æ‰©å±•æ¯”ä¾‹ |

### è®­ç»ƒè„šæœ¬å‚æ•°

#### é€šç”¨å‚æ•°
```bash
# æ•°æ®é›†è®¾ç½®
--dataset-type {modelnet,shapenet2,c3vd}  # æ•°æ®é›†ç±»å‹
--dataset-path PATH                       # æ•°æ®é›†è·¯å¾„
--num-points 1024                        # æ¯ä¸ªç‚¹äº‘çš„ç‚¹æ•°

# æ¨¡å‹è®¾ç½®
--model-type {pointnet,attention,mamba3d} # æ¨¡å‹ç±»å‹é€‰æ‹©
--dim-k 1024                             # ç‰¹å¾ç»´åº¦
--symfn {max,avg,selective}              # èšåˆå‡½æ•°

# Mamba3Dä¸“ç”¨å‚æ•°
--num-mamba-blocks 3                     # Mambaå—æ•°é‡
--d-state 16                             # çŠ¶æ€ç©ºé—´ç»´åº¦
--expand 2                               # ç‰¹å¾æ‰©å±•æ¯”ä¾‹

# è®­ç»ƒè®¾ç½®  
--epochs 200                             # è®­ç»ƒè½®æ•°
--batch-size 32                          # æ‰¹æ¬¡å¤§å°
--optimizer {Adam,SGD}                   # ä¼˜åŒ–å™¨é€‰æ‹©
--cosine-annealing                       # ä½™å¼¦é€€ç«å­¦ä¹ ç‡
```

#### PointLKä¸“ç”¨å‚æ•°
```bash
--max-iter 10                            # LKæœ€å¤§è¿­ä»£æ¬¡æ•°
--delta 1e-2                             # é›…å¯æ¯”è¿‘ä¼¼æ­¥é•¿
--learn-delta                            # å­¦ä¹ æ­¥é•¿å‚æ•°
--mag 0.8                                # è®­ç»ƒæ—¶æ‰°åŠ¨å¹…åº¦
```

## ğŸ“Š æ€§èƒ½ç‰¹å¾å¯¹æ¯”

### è®¡ç®—å¤æ‚åº¦åˆ†æ

| æ¨¡å‹ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹å¾è¡¨è¾¾èƒ½åŠ› | é€‚ç”¨åœºæ™¯ |
|------|------------|------------|--------------|----------|
| **PointNet** | O(N) | O(N) | åŸºç¡€ | ç®€å•ç‚¹äº‘ä»»åŠ¡ |
| **AttentionNet** | O(NÂ²) | O(NÂ²) | å¼ºå¤§ | å¤æ‚å‡ ä½•ç†è§£ |
| **Mamba3D** | O(N) | O(N) | å¼ºå¤§ | å¤§è§„æ¨¡ç‚¹äº‘å¤„ç† |

### å†…å­˜ä½¿ç”¨æŒ‡å—

| é…ç½®çº§åˆ« | GPUå†…å­˜éœ€æ±‚ | æ¨èå‚æ•° | é€‚ç”¨åœºæ™¯ |
|----------|-------------|----------|----------|
| **è½»é‡çº§** | < 4GB | `dim_k=512, blocks=2, d_state=8` | ç§»åŠ¨è®¾å¤‡/è¾¹ç¼˜è®¡ç®— |
| **æ ‡å‡†** | 4-8GB | `dim_k=1024, blocks=3, d_state=16` | ä¸€èˆ¬åº”ç”¨ |
| **é«˜æ€§èƒ½** | > 8GB | `dim_k=1024, blocks=4, d_state=32` | ç ”ç©¶å®éªŒ |

### è®­ç»ƒæ—¶é—´é¢„ä¼°

```bash
# åŸºäº1024ç‚¹ï¼Œ32æ‰¹æ¬¡å¤§å°çš„å…¸å‹è®­ç»ƒæ—¶é—´ (å•GPU)
PointNet:     ~2-3 ç§’/è½®  (100-200è½®æ”¶æ•›)
AttentionNet: ~8-12ç§’/è½®  (150-300è½®æ”¶æ•›)
Mamba3D:      ~4-6ç§’/è½®   (120-250è½®æ”¶æ•›)

# å¤šGPUå¹¶è¡Œå¯æ˜¾è‘—åŠ é€Ÿè®­ç»ƒ
```

## ğŸ”§ é«˜çº§é…ç½®ä¸ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–ç­–ç•¥

```python
# æ¢¯åº¦æ£€æŸ¥ç‚¹ (å‡å°‘å†…å­˜ä½¿ç”¨)
from torch.utils.checkpoint import checkpoint

# ä½¿ç”¨é«˜çº§Mamba3Dç‰¹å¾æå–å™¨
from ptlk.mamba3d_v1 import AdvancedMamba3D_features

# åˆ›å»ºå¸¦æ£€æŸ¥ç‚¹çš„ç‰¹å¾æå–å™¨
model = AdvancedMamba3D_features(
    dim_k=1024,
    use_checkpoint=True,  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    adaptive_computation=False  # æ˜¯å¦å¯ç”¨è‡ªé€‚åº”è®¡ç®—
)

# æ··åˆç²¾åº¦è®­ç»ƒ (å‡å°‘å†…å­˜ï¼ŒåŠ é€Ÿè®­ç»ƒ)
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    output = model(inputs)
    loss = criterion(output, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### 2. åŠ¨æ€è°ƒæ•´ç­–ç•¥

```python
# è‡ªé€‚åº”çŠ¶æ€ç»´åº¦
def adaptive_state_dim(epoch, base_state=16):
    """è®­ç»ƒåˆæœŸä½¿ç”¨è¾ƒå°çŠ¶æ€ç»´åº¦ï¼ŒåæœŸå¢åŠ å¤æ‚åº¦"""
    if epoch < 50:
        return base_state // 2
    elif epoch < 100:
        return base_state
    else:
        return base_state * 2

# æ¸è¿›å¼è®­ç»ƒç­–ç•¥
def progressive_training(model, epoch):
    """é€æ­¥å¢åŠ æ¨¡å‹å¤æ‚åº¦"""
    if epoch < 30:
        # å‰30è½®åªè®­ç»ƒåŸºç¡€å±‚
        for i, block in enumerate(model.mamba_blocks):
            if i > 1:
                for param in block.parameters():
                    param.requires_grad = False
    else:
        # 30è½®åå¼€æ”¾æ‰€æœ‰å±‚
        for param in model.parameters():
            param.requires_grad = True
```

### 3. æ•°æ®å¢å¼ºç­–ç•¥

```python
# é’ˆå¯¹ç‚¹äº‘çš„æ•°æ®å¢å¼º
class PointCloudAugmentation:
    def __init__(self):
        self.transforms = [
            self.random_rotation,
            self.random_scaling,
            self.random_jitter,
            self.random_dropout
        ]
    
    def random_rotation(self, points):
        """éšæœºæ—‹è½¬å¢å¼ºå‡ ä½•ä¸å˜æ€§"""
        angle = torch.rand(1) * 2 * math.pi
        rotation_matrix = self.get_rotation_matrix(angle)
        return torch.matmul(points, rotation_matrix)
    
    def random_scaling(self, points):
        """éšæœºç¼©æ”¾å¢å¼ºå°ºåº¦ä¸å˜æ€§"""
        scale = 0.8 + torch.rand(1) * 0.4  # [0.8, 1.2]
        return points * scale
    
    def random_jitter(self, points):
        """æ·»åŠ å™ªå£°æé«˜é²æ£’æ€§"""
        noise = torch.randn_like(points) * 0.01
        return points + noise
    
    def random_dropout(self, points):
        """éšæœºä¸¢å¼ƒç‚¹æ¨¡æ‹Ÿé®æŒ¡"""
        keep_ratio = 0.8 + torch.rand(1) * 0.15  # [0.8, 0.95]
        num_keep = int(points.shape[1] * keep_ratio)
        indices = torch.randperm(points.shape[1])[:num_keep]
        return points[:, indices, :]
```

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### åŠŸèƒ½æµ‹è¯•
```bash
# å®Œæ•´åŠŸèƒ½æµ‹è¯• (éœ€è¦PyTorchç¯å¢ƒ)
python test_mamba3d.py

# å¿«é€Ÿè¯­æ³•æ£€æŸ¥ (æ— éœ€æ·±åº¦å­¦ä¹ ä¾èµ–)
python -m py_compile ptlk/mamba3d_v1.py
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•
```python
import time
import torch
from ptlk.mamba3d_v1 import Mamba3D_features
from ptlk.attention_v1 import AttentionNet_features
from ptlk.pointnet import PointNet_features

def benchmark_models():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    points = torch.randn(32, 1024, 3).to(device)
    
    # PointNetåŸºå‡†
    pointnet = PointNet_features().to(device)
    start_time = time.time()
    for _ in range(100):
        _ = pointnet(points)
    pointnet_time = time.time() - start_time
    
    # AttentionNetåŸºå‡†
    attention = AttentionNet_features().to(device)
    start_time = time.time()
    for _ in range(100):
        _ = attention(points)
    attention_time = time.time() - start_time
    
    # Mamba3DåŸºå‡†
    mamba = Mamba3D_features().to(device)
    start_time = time.time()
    for _ in range(100):
        _ = mamba(points)
    mamba_time = time.time() - start_time
    
    print(f"PointNetå¹³å‡æ—¶é—´: {pointnet_time/100:.4f}ç§’")
    print(f"AttentionNetå¹³å‡æ—¶é—´: {attention_time/100:.4f}ç§’")
    print(f"Mamba3Då¹³å‡æ—¶é—´: {mamba_time/100:.4f}ç§’")
    print(f"é€Ÿåº¦æ¯”ç‡: AttentionNet/PointNet={attention_time/pointnet_time:.2f}x")
    print(f"é€Ÿåº¦æ¯”ç‡: Mamba3D/PointNet={mamba_time/pointnet_time:.2f}x")
    print(f"é€Ÿåº¦æ¯”ç‡: Mamba3D/AttentionNet={mamba_time/attention_time:.2f}x")

benchmark_models()
```

## ğŸ“š ç†è®ºèƒŒæ™¯ä¸å‚è€ƒæ–‡çŒ®

### æ ¸å¿ƒç†è®ºåŸºç¡€

1. **Mambaæ¨¡å‹**: Gu et al. "Mamba: Linear-Time Sequence Modeling with Selective State Spaces" (2023)
   - é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹çš„é«˜æ•ˆå®ç°
   - çº¿æ€§å¤æ‚åº¦çš„åºåˆ—å»ºæ¨¡

2. **çŠ¶æ€ç©ºé—´æ¨¡å‹**: Gu et al. "Efficiently Modeling Long Sequences with Structured State Spaces" (2021)
   - SSMçš„åŸºç¡€ç†è®ºä¸ç¦»æ•£åŒ–æ–¹æ³•
   - é•¿åºåˆ—å»ºæ¨¡çš„é«˜æ•ˆæ–¹æ³•

3. **PointNetæ¶æ„**: Qi et al. "PointNet: Deep Learning on Point Sets" (2017)
   - ç½®æ¢ä¸å˜æ€§çš„é‡è¦æ€§
   - ç‚¹äº‘çš„èšåˆç­–ç•¥è®¾è®¡

4. **PointNetLKç®—æ³•**: Aoki et al. "PointNetLK: Robust & Efficient Point Cloud Registration" (2019)
   - Lucas-Kanadeè¿­ä»£ä¼˜åŒ–
   - ç‰¹å¾ç©ºé—´ä¸­çš„é…å‡†ç®—æ³•

### æ”¹è¿›ä¸åˆ›æ–°ç‚¹

1. **3D-SSMè®¾è®¡**: å°†åŸå§‹Mamba SSMæ‰©å±•åˆ°3Dç‚¹äº‘é¢†åŸŸ
2. **å¤šå°ºåº¦çŠ¶æ€ç©ºé—´**: ä»å±€éƒ¨å‡ ä½•åˆ°å…¨å±€ç»“æ„çš„å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹ 
3. **è‡ªé€‚åº”è®¡ç®—**: æ ¹æ®ç‚¹çš„é‡è¦æ€§åŠ¨æ€åˆ†é…è®¡ç®—èµ„æº
4. **çº¿æ€§æ‰©å±•æ€§**: å¯¹å¤§è§„æ¨¡ç‚¹äº‘çš„é«˜æ•ˆå¤„ç†

## ğŸ¤ å¼€å‘æŒ‡å—

### æ‰©å±•æ–°åŠŸèƒ½

```python
# 1. æ·»åŠ æ–°çš„èšåˆå‡½æ•°
def symfn_hierarchical(x, num_levels=3):
    """åˆ†å±‚æ¬¡èšåˆ"""
    features = []
    batch_size, num_points, dim = x.shape
    
    # ä¸åŒç²’åº¦çš„èšåˆ
    for i in range(num_levels):
        # é‡‡æ ·ç‚¹æ•°
        sample_size = num_points // (2**i)
        # éšæœºé‡‡æ ·
        indices = torch.randperm(num_points)[:sample_size]
        # èšåˆ
        feat = torch.max(x[:, indices, :], dim=1)[0]
        features.append(feat)
    
    # æ‹¼æ¥ä¸åŒç²’åº¦çš„ç‰¹å¾
    return torch.cat(features, dim=1)

# 2. åŒå‘Mambaå—
class BiDirectionalMamba3DBlock(nn.Module):
    """åŒå‘Mambaå—ï¼Œæ•è·æ­£å‘å’Œåå‘çš„ç©ºé—´ä¾èµ–"""
    def __init__(self, d_model, d_state=16):
        super().__init__()
        self.forward_mamba = S6Layer(d_model, d_state)
        self.backward_mamba = S6Layer(d_model, d_state)
        self.fusion = nn.Linear(d_model*2, d_model)
        
    def forward(self, x):
        # æ­£å‘å¤„ç†
        forward_features = self.forward_mamba(x)
        
        # åå‘å¤„ç† (ç¿»è½¬ç‚¹åºåˆ—)
        x_reverse = torch.flip(x, dims=[1])
        backward_features = self.backward_mamba(x_reverse)
        backward_features = torch.flip(backward_features, dims=[1])
        
        # èåˆç‰¹å¾
        combined = torch.cat([forward_features, backward_features], dim=-1)
        output = self.fusion(combined)
        
        return output

# 3. ç¨€ç–ç‚¹äº‘å¤„ç†
class SparseMamba3D(nn.Module):
    """ç¨€ç–ç‚¹äº‘å¤„ç†ï¼Œé€‚ç”¨äºå¤§åœºæ™¯ç‚¹äº‘"""
    def __init__(self, voxel_size=0.1):
        super().__init__()
        self.voxel_size = voxel_size
        self.mamba_model = Mamba3D_features(dim_k=1024)
        
    def voxelize(self, points):
        """ä½“ç´ åŒ–ç‚¹äº‘"""
        # å°†ç‚¹äº‘åæ ‡é™¤ä»¥ä½“ç´ å¤§å°å¹¶å–æ•´ï¼Œå¾—åˆ°ä½“ç´ ç´¢å¼•
        voxel_indices = (points / self.voxel_size).int()
        
        # ä¸ºæ¯ä¸ªä½“ç´ é€‰æ‹©ä¸­å¿ƒç‚¹
        unique_indices, inverse = torch.unique(voxel_indices, dim=1, return_inverse=True)
        
        # æ”¶é›†æ¯ä¸ªä½“ç´ ä¸­çš„ç‚¹
        voxelized_points = []
        for i in range(len(unique_indices)):
            mask = (inverse == i)
            points_in_voxel = points[:, mask, :]
            # å–å¹³å‡å€¼ä½œä¸ºä½“ç´ ä¸­å¿ƒ
            center = points_in_voxel.mean(dim=1, keepdim=True)
            voxelized_points.append(center)
        
        return torch.cat(voxelized_points, dim=1)
    
    def forward(self, points):
        # ä½“ç´ åŒ–å¤„ç†
        if points.shape[1] > 10000:  # å¯¹äºå¤§ç‚¹äº‘è¿›è¡Œä½“ç´ åŒ–
            voxelized_points = self.voxelize(points)
        else:
            voxelized_points = points
            
        # Mambaå¤„ç†
        features = self.mamba_model(voxelized_points)
        return features
```

### è´¡çŒ®ä»£ç 

1. **ä»£ç è§„èŒƒ**: éµå¾ªPEP 8æ ‡å‡†ï¼Œæ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
2. **æµ‹è¯•ç”¨ä¾‹**: ä¸ºæ–°åŠŸèƒ½ç¼–å†™ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹
3. **æ€§èƒ½åŸºå‡†**: æä¾›æ€§èƒ½å¯¹æ¯”æ•°æ®
4. **æ–‡æ¡£æ›´æ–°**: æ›´æ–°READMEå’ŒAPIæ–‡æ¡£

## ğŸ¯ åº”ç”¨åœºæ™¯

### 1. 3Dç›®æ ‡æ£€æµ‹
```python
# ç»“åˆMamba3Dè¿›è¡Œ3Dç›®æ ‡æ£€æµ‹
class PointCloudDetector(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.backbone = Mamba3D_features(dim_k=512)
        self.bbox_head = nn.Linear(512, num_classes * 7)  # cls + bbox
        
    def forward(self, points):
        features = self.backbone(points)
        predictions = self.bbox_head(features)
        return predictions.view(-1, num_classes, 7)
```

### 2. ç‚¹äº‘åˆ†å‰²
```python
# ç‚¹çº§åˆ†å‰²ä»»åŠ¡
class PointSegmentation(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.mamba_net = Mamba3D_features(dim_k=256)
        self.seg_head = nn.Conv1d(256, num_classes, 1)
        
    def forward(self, points):
        # è·å–æ¯ç‚¹ç‰¹å¾è€Œéå…¨å±€ç‰¹å¾
        point_features = self.mamba_net.get_point_features(points)
        segmentation = self.seg_head(point_features.transpose(1, 2))
        return segmentation.transpose(1, 2)
```

### 3. åœºæ™¯ç†è§£
```python
# å®¤å†…åœºæ™¯ç†è§£
class SceneUnderstanding(nn.Module):
    def __init__(self):
        super().__init__()
        self.mamba_net = Mamba3D_features(dim_k=1024)
        self.scene_classifier = nn.Linear(1024, 10)  # æˆ¿é—´ç±»å‹
        self.object_detector = nn.Linear(1024, 20 * 6)  # ç‰©ä½“+ä½ç½®
        
    def forward(self, points):
        global_features = self.mamba_net(points)
        scene_type = self.scene_classifier(global_features)
        object_detections = self.object_detector(global_features)
        return scene_type, object_detections
```

## ğŸš¨ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. å†…å­˜ä¸è¶³ (OOM)
```python
# è§£å†³æ–¹æ¡ˆ1: å‡å°‘æ‰¹æ¬¡å¤§å°å’Œç‚¹æ•°
--batch-size 16 --num-points 512

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
from ptlk.mamba3d_v1 import AdvancedMamba3D_features
model = AdvancedMamba3D_features(use_checkpoint=True)

# è§£å†³æ–¹æ¡ˆ3: åˆ†æ®µå¤„ç†å¤§ç‚¹äº‘
def process_large_pointcloud(points, chunk_size=1024):
    results = []
    for i in range(0, points.shape[1], chunk_size):
        chunk = points[:, i:i+chunk_size, :]
        result = model(chunk)
        results.append(result)
    return torch.cat(results, dim=1)
```

### 2. è®­ç»ƒä¸æ”¶æ•›
```python
# è§£å†³æ–¹æ¡ˆ1: è°ƒæ•´å­¦ä¹ ç‡
optimizer = torch.optim.Adam(params, lr=1e-4)  # é™ä½å­¦ä¹ ç‡
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)

# è§£å†³æ–¹æ¡ˆ2: æ¢¯åº¦è£å‰ª
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# è§£å†³æ–¹æ¡ˆ3: é¢„çƒ­è®­ç»ƒ
def warmup_learning_rate(epoch, base_lr, warmup_epochs=10):
    if epoch < warmup_epochs:
        return base_lr * (epoch + 1) / warmup_epochs
    return base_lr
```

### 3. æ¨ç†é€Ÿåº¦æ…¢
```python
# è§£å†³æ–¹æ¡ˆ1: æ¨¡å‹é‡åŒ–
import torch.quantization as quantization
quantized_model = quantization.quantize_dynamic(model, dtype=torch.qint8)

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨æ›´å°çš„çŠ¶æ€ç»´åº¦
model = Mamba3D_features(d_state=8, num_mamba_blocks=2)

# è§£å†³æ–¹æ¡ˆ3: å¯¼å‡ºä¸ºONNXæ ¼å¼åŠ é€Ÿæ¨ç†
import torch.onnx
torch.onnx.export(model, example_input, "mamba3d.onnx")
```

---

## ğŸ‰ æ€»ç»“

Mamba3Då·²æˆåŠŸé›†æˆåˆ°PointNetLKé¡¹ç›®ä¸­ï¼Œæä¾›äº†çº¿æ€§å¤æ‚åº¦çš„ç‚¹äº‘ç‰¹å¾å­¦ä¹ èƒ½åŠ›ã€‚é€šè¿‡å®Œæ•´çš„APIå…¼å®¹æ€§è®¾è®¡ï¼Œç”¨æˆ·å¯ä»¥æ— ç¼æ›¿æ¢åŸæœ‰çš„PointNetæ¨¡å—ï¼Œäº«å—çŠ¶æ€ç©ºé—´æ¨¡å‹å¸¦æ¥çš„æ€§èƒ½å’Œæ•ˆç‡æå‡ã€‚

æ— è®ºæ˜¯ç‚¹äº‘é…å‡†ã€åˆ†ç±»è¿˜æ˜¯å…¶ä»–ä¸‰ç»´ç†è§£ä»»åŠ¡ï¼ŒMamba3Déƒ½èƒ½æä¾›æ›´é«˜æ•ˆçš„ç‰¹å¾è¡¨ç¤ºå’Œæ›´å¥½çš„å¯æ‰©å±•æ€§ã€‚ç»“åˆè¯¦ç»†çš„é…ç½®é€‰é¡¹å’Œä¼˜åŒ–ç­–ç•¥ï¼Œæœ¬å®ç°æ—¢é€‚åˆç ”ç©¶æ¢ç´¢ï¼Œä¹Ÿå…·å¤‡å·¥ä¸šåº”ç”¨çš„å®ç”¨æ€§ã€‚

**ğŸš€ ç°åœ¨å°±å¼€å§‹ä½¿ç”¨Mamba3Dï¼Œä½“éªŒä¸‹ä¸€ä»£ç‚¹äº‘æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼** 